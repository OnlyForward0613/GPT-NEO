{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPTNeo_example_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0i5MRP0SV8D"
      },
      "source": [
        "Welcome to the colab notebook for [GPTNeo](https://github.com/EleutherAI/GPTNeo) - a fully open source implementation of GPT like models for mesh-tensorflow by [EleutherAI](eleuther.ai).\n",
        "\n",
        "Our library provides training and inference for GPT models up to GPT3 sizes on both TPUs and GPUs. \n",
        "\n",
        "In this notebook we walk you through TPU training (or finetuning!) and sampling using the freely available colab TPUs.\n",
        "\n",
        "If you find our repo useful, come join [our discord](https://discord.gg/BK2v3EJ) and say hi! 😬\n",
        "\n",
        "Before we get going - make sure you are running this notebook with a TPU available. Go to Runtime -> Change Runtime Type and select 'TPU' under hardware accelerator.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-53qkZV6Lv9",
        "cellView": "form"
      },
      "source": [
        "#@title Setup\n",
        "%tensorflow_version 2.x\n",
        "!git clone https://github.com/EleutherAI/GPTNeo\n",
        "%cd GPTNeo\n",
        "!pip3 install -q -r requirements.txt\n",
        "pretrained_model = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0R1owh2qvp8"
      },
      "source": [
        "## Set Google Cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PmzM4dy7diP"
      },
      "source": [
        "To train on TPUs we need to store our data on a google cloud bucket - as TPUs can't read from local filesystems.\n",
        "\n",
        "You can set up a bucket by signing up for a free trial here: https://console.cloud.google.com/\n",
        "\n",
        "Make a bucket at https://console.cloud.google.com/storage and come back when that's done.\n",
        "\n",
        "The next cell sets up google authentication and gives the notebook read and write access to your bucket.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bQUjPA7qvj"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr_c6A2NBK5i",
        "cellView": "form"
      },
      "source": [
        "path_to_cloud_bucket = 'gs://your-cloud-bucket/' #@param {type:\"string\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZGbzUPD0tad"
      },
      "source": [
        "## Set Up Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R918l14UhrBR"
      },
      "source": [
        "We first need to download and tokenize a dataset - you can choose from:\n",
        "\n",
        "*   Sampling Only - choose this option if you only wish to sample from our trained models.\n",
        "\n",
        "*   OpenWebText - an opensource clone of OpenAI's WebText dataset, the original training data of GPT2.\n",
        "\n",
        "*   YoutubeSubtitles - a dataset of subtitles scraped from youtube videos.\n",
        "\n",
        "* Hackernews - comments scraped from hackernews\n",
        "\n",
        "* NIHExporter - Data relating to various projects from the national institute of health.\n",
        "\n",
        "* Custom - if this option is chosen you will be prompted to enter the path to your own dataset. It should be a directory containing .txt or .jsonl files.\n",
        "\n",
        "All these datasets are from EleutherAI's side project - [The Pile™](https://github.com/EleutherAI/The-Pile) - an effort to gather a general purpose, diverse and open source plain text dataset large enough to train 1T+ parameter language models.\n",
        "\n",
        "Even the smallest datasets are fairly large files, so this step will likely take a while. Select a dataset in the next cell, then run the next two cells, and go grab a snack and a cup of tea 😊\n",
        "\n",
        "Alternatively, you can provide your own dataset in the form of a folder or gzip archive of .txt files. Simply select 'Custom' below and follow input the path to your data and the name of your dataset when prompted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM8jP3Am_hsx",
        "cellView": "form"
      },
      "source": [
        "# Select a Dataset:\n",
        "import os\n",
        "dataset = 'Sampling_Only' #@param [\"Sampling_Only\", \"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom\"]\n",
        "\n",
        "if dataset == \"Sampling_Only\":\n",
        "  pass\n",
        "elif dataset == 'OpenWebText':\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar -O openwebtext.tar.xz\n",
        "  !tar xf openwebtext.tar.xz\n",
        "  dataset_path = \"openwebtext\"\n",
        "  dataset_name = dataset_path\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'YoutubeSubtitles':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/yt_subs.jsonl.zst -O data/yt_subs.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'ytsubs'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'HackerNews':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/hn.tar.gz -O data/hn.tar.gz\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'hackernews'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == \"NIHExporter\":\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/NIH_ExPORTER_awarded_grant_text.jsonl.zst -O data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  os.system('mv NIH_ExPORTER_awarded_grant_text.jsonl.zst ./data')\n",
        "  dataset_name = 'nihexporter'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == \"Custom\":\n",
        "  dataset_path = input('Enter the path to the folder containing your data: ')\n",
        "  dataset_name = input('Enter the name of your dataset: ')\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "else:\n",
        "  raise NotImplementedError('please select from available options: [\"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom\"]')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMl1cHtN5I_W"
      },
      "source": [
        "### Tokenize and Upload Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IBIompTJaqm"
      },
      "source": [
        "Now tokenize the dataset and copy it over to your google cloud bucket. You may skip this step if you are sampling from a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq5u0WUSJWwz",
        "cellView": "both"
      },
      "source": [
        "# Tokenize Data\n",
        "!python data/create_tfrecords.py --input_dir /content/GPTNeo/$dataset_path --name $dataset_name --files_per 1000 --output_dir $out_name --write_dataset_config --processes 1\n",
        "\n",
        "# copy the data to your bucket\n",
        "if not path_to_cloud_bucket.endswith('/'):\n",
        "  path_to_cloud_bucket += '/'\n",
        "copy_loc = path_to_cloud_bucket + \"datasets/\" + dataset\n",
        "!gsutil -m cp -r /content/GPTNeo/$out_name $copy_loc\n",
        "!gsutil ls $path_to_cloud_bucket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhvmTFD7b_fb"
      },
      "source": [
        "Before starting training - you'll need to edit your dataset & model configs to point to your buckets / data. You need to do this even if you are sampling from a pre-trained model.\n",
        "\n",
        "*   First change the writefile path to point to your chosen dataset - e.g `%%writefile configs/dataset_configs/ytsubs.json`\n",
        "*   Change the \"path\" field to point to your cloud bucket location - e.g `gs://neo_lmdatasets/datasets/ytsubs_*.tfrecords`\n",
        "* Change `dataset_name` in `%%writefile configs/dataset_configs/dataset_name.json` to the name of your chosen dataset.\n",
        "* Once you've made the edits, then run the cell below to overwrite the existing files.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCsZP48vavCP"
      },
      "source": [
        "%%writefile configs/dataset_configs/Sampling_Only.json\n",
        "\n",
        "{\n",
        "  \"path\": \"gs://eleutherai/datasets/Sampling_Only/Sampling_Only*.tfrecords\",\n",
        "  \"eval_path\": \"\",\n",
        "  \"n_vocab\": 50256,\n",
        "  \"tokenizer_is_pretrained\": true,\n",
        "  \"tokenizer_path\": \"gpt2\",\n",
        "  \"eos_id\": 50256,\n",
        "  \"padding_id\": 50257\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH0x3dI9j85P"
      },
      "source": [
        "## Set Model Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6GnCgAkB7GQ"
      },
      "source": [
        "The model below is identical to our pretrained GPT3XL model (1.3B Params). \n",
        "\n",
        "If you want to use a smaller model, you can modify any of the config files in ../configs/ ending in _8.json, all of which are designed to train on tpu-v8s.\n",
        "\n",
        "For a more detailed breakdown on what each item in the configuration file means - please read through our training and config guides in our [github README](https://github.com/EleutherAI/GPTNeo#training-guide). \n",
        "\n",
        "You'll want to change the first item in the `datasets` list to the name of your chosen dataset. (the filename minus .json in ./configs/dataset_configs)\n",
        "\n",
        "You'll also want to modify the `model_path` field to point to your google cloud bucket, so checkpoints get saved to there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9hUDdokiWj6"
      },
      "source": [
        "%%writefile configs/GPT3_XL.json\n",
        "\n",
        "{\n",
        "    \"n_head\": 16,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"embed_dropout\": 0,\n",
        "    \"lr\": 0.0002,\n",
        "    \"lr_decay\": \"cosine\",\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0,\n",
        "    \"train_batch_size\": 256,\n",
        "    \"attn_dropout\": 0,\n",
        "    \"train_steps\": 600000,\n",
        "    \"eval_steps\": 0,\n",
        "    \"predict_steps\": 1,\n",
        "    \"res_dropout\": 0,\n",
        "    \"eval_batch_size\": 4,\n",
        "    \"predict_batch_size\": 1,\n",
        "    \"iterations\": 100,\n",
        "    \"n_embd\": 2048,\n",
        "    \"datasets\": [[\"HackerNews\", null, null, null]],\n",
        "    \"model\": \"GPT\",\n",
        "    \"model_path\": \"gs://eleutherai/GPT3_XL\",\n",
        "    \"n_ctx\": 2048,\n",
        "    \"n_layer\": 24,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": false,\n",
        "    \"attention_types\" :  [[[\"global\", \"local\"],12]],\n",
        "    \"mesh_shape\": \"x:4,y:2\",\n",
        "    \"layout\": \"intermediate_expanded:x,heads:x,vocab:n_vocab,memory_length:y,embd:y\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"recompute_grad\": true,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"tokens_per_mb_per_replica\": 2048,\n",
        "    \"precision\": \"bfloat16\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWK9MJqwcXKn"
      },
      "source": [
        "## Training from Scratch\n",
        "\n",
        "Now we will begin to train the model. If no previous model is found in \"model_path\", the model will start training from scratch. If you'd prefer to finetune from pretrained, skip to the `Finetune a Pretrained Model` section.\n",
        "\n",
        "If everything's set up correctly, you can now run the main.py function to start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUtrysOSBzjJ"
      },
      "source": [
        "!python3 main.py --model colab_XL --steps_per_checkpoint 500 --tpu colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koKQHA5ikCvD"
      },
      "source": [
        "## Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QZv4_pnkk26"
      },
      "source": [
        "If you want to sample from or finetune a pretrained model, EleutherAI has pretrained two models for release. One with [1.3B parameters](https://the-eye.eu/public/AI/gptneo-release/GPT3_XL/), and another with [2.7B](https://the-eye.eu/public/AI/gptneo-release/GPT3_2-7B/). \n",
        "\n",
        "Select an option below to download the weights locally. You will then need to upload them to your cloud bucket in order to finetune from them. If the download command isn't working, try the commented out code to download from a different source.\n",
        "\n",
        "The 2-7B model likely won't fit into the colab TPUs memory, and you may have to get some larger pods to finetune from it.\n",
        "\n",
        "Sampling from it, however, works just fine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgTG1ammqGB0"
      },
      "source": [
        "# @title Download pretrained model weights:\n",
        "pretrained_model = 'GPT3_XL' #@param [\"GPT3_XL\", \"GPT3_2-7B\"]\n",
        "!wget -m -np -c -U \"eye02\" -w 2 -R \"index.html*\" \"https://the-eye.eu/public/AI/gptneo-release/$pretrained_model/\"\n",
        "path_to_local_weights = f\"/content/GPTNeo/the-eye.eu/public/AI/gptneo-release/{pretrained_model}\"\n",
        "\n",
        "# URL = f\"http://eaidata.bmk.sh/data/gptneo-release/{pretrained_model}/\"\n",
        "# FOLDER_NAME = \"GPT3_XL\"\n",
        "# !curl $URL | grep -i \"</a>\" | sed -n 's/.*href=\"\\([^\"]*\\).*/\\1/p' | sed \"s|^|$URL|\" | xargs -n 1 -P 4 wget -P $pretrained_model\n",
        "# path_to_local_weights = pretrained_model\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU3BDNJN_ZXE"
      },
      "source": [
        "# upload to your bucket\n",
        "bucket_base = \"gs://\" + path_to_cloud_bucket.replace('gs://', '').split('/')[0]\n",
        "!gsutil -m cp -r $path_to_local_weights $bucket_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnqkKBTOn0ox"
      },
      "source": [
        "If everything has worked successfully you should now see your model listed in your bucket below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80t9MMionm2h"
      },
      "source": [
        "!gsutil ls $bucket_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDKL8fCSoApL"
      },
      "source": [
        "Now we want to make a few modifications to the model config in order to get training working on colab and finetune on your chosen dataset. If you are sampling from our pretrained models, you do not need to make any modifications.\n",
        "\n",
        "You can change parameters below. \n",
        "\n",
        "* `path_to_model` should point to the model weights location in your cloud bucket, and will default to `$bucket_base/${pretrained_model}` if nothing is entered.\n",
        "\n",
        "* `batch_size` is your train batch size - if you're encountering memory errors, try lowering this.\n",
        "\n",
        "* `dataset_name` is the name of your dataset, if nothing is entered, this should default to the dataset you selected in the `Prepare Data` section.\n",
        "\n",
        "* `mesh_shape` specifies the way the model will be divided up across the TPU cores. We suggest leaving this alone unless you know what you're doing.\n",
        "\n",
        "* `train_steps` specifies how many steps you want the model to finetune for. We set this to 1000 for demonstrative purposes but you may need to increase this a little depending on your goals.\n",
        "\n",
        "* `steps_per_checkpoint` specifies how often you want to save model weights during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Laf0slBMDCUj",
        "cellView": "form",
        "outputId": "b2213b59-3de0-41d0-f991-484483452f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Modify config for colab. \n",
        "  \n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "path_to_model = \"\" #@param {type:\"string\"}\n",
        "batch_size = 16 #@param {type:\"integer\"}\n",
        "dset = \"\"  #@param {type:\"string\"}\n",
        "mesh_shape = \"x:4,y:2\" #@param {type:\"string\"}\n",
        "train_steps = 1000 #@param {type:\"integer\"}\n",
        "steps_per_checkpoint = 500 #@param {type:\"integer\"}\n",
        "start_step = 400000 if pretrained_model == \"GPT3_2-7B\" else 362000\n",
        "\n",
        "if path_to_model == \"\":\n",
        "  path_to_model = f'{bucket_base.strip(\"/\")}/{pretrained_model}'\n",
        "print(f'MODEL PATH: {path_to_model}\\n')\n",
        "\n",
        "if dset == \"\" and dataset != \"Sampling_Only\":\n",
        "  dset = dataset\n",
        "\n",
        "def pad_to_multiple_of(n, mult):\n",
        "  \"\"\"\n",
        "  pads n to a multiple of mult\n",
        "  \"\"\"\n",
        "  extra = n % mult\n",
        "  if extra > 0:\n",
        "      n = n + mult - extra\n",
        "  return n\n",
        "\n",
        "with open(f'{path_to_local_weights}/config.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "  pprint(data)\n",
        "  dset_val = [[dataset, None, None, None]] if dset != \"\" else data[\"datasets\"]\n",
        "  mods = {\n",
        "          \"mesh_shape\": mesh_shape,\n",
        "          \"layout\": \"intermediate_expanded:x,heads:x,memory_length:y,embd:y\",\n",
        "          \"model_path\": path_to_model,\n",
        "          \"datasets\": dset_val,\n",
        "          \"train_steps\": start_step + train_steps,\n",
        "          \"eval_steps\": 0,\n",
        "          \"train_batch_size\": batch_size\n",
        "        }\n",
        "  data.update(mods)\n",
        "  print('\\n--->\\n')\n",
        "  pprint(data)\n",
        "  with open(f'configs/{pretrained_model}.json', 'w') as outfile:\n",
        "    json.dump(data, outfile, indent=2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL PATH: gs://test-bucket-neo/GPT3_XL\n",
            "\n",
            "{'activation_function': 'gelu',\n",
            " 'attention_types': [[['global', 'local'], 12]],\n",
            " 'attn_dropout': 0,\n",
            " 'beta1': 0.9,\n",
            " 'beta2': 0.95,\n",
            " 'datasets': [['pile', None, None, None]],\n",
            " 'embed_dropout': 0,\n",
            " 'eos_id': 50256,\n",
            " 'epsilon': 1e-08,\n",
            " 'eval_batch_size': 128,\n",
            " 'eval_steps': 10,\n",
            " 'gradient_clipping': 1.0,\n",
            " 'iterations': 500,\n",
            " 'layout': 'batch:x,memory_length:y,embd:y',\n",
            " 'lr': 0.0002,\n",
            " 'lr_decay': 'cosine',\n",
            " 'lr_decay_end': 300000,\n",
            " 'mesh_shape': 'x:128,y:2',\n",
            " 'model_path': 'gs://neo-d/models/GPT3_XL_Pile',\n",
            " 'n_ctx': 2048,\n",
            " 'n_embd': 2048,\n",
            " 'n_head': 16,\n",
            " 'n_layer': 24,\n",
            " 'n_vocab': 50257,\n",
            " 'opt_name': 'adam',\n",
            " 'padding_id': 50257,\n",
            " 'precision': 'bfloat16',\n",
            " 'predict_batch_size': 128,\n",
            " 'predict_steps': 0,\n",
            " 'recompute_grad': True,\n",
            " 'res_dropout': 0,\n",
            " 'scale_by_depth': True,\n",
            " 'scale_by_in': False,\n",
            " 'tokens_per_mb_per_replica': 4096,\n",
            " 'train_batch_size': 512,\n",
            " 'train_steps': 400000,\n",
            " 'warmup_steps': 3000,\n",
            " 'weight_decay': 0}\n",
            "\n",
            "--->\n",
            "\n",
            "{'activation_function': 'gelu',\n",
            " 'attention_types': [[['global', 'local'], 12]],\n",
            " 'attn_dropout': 0,\n",
            " 'beta1': 0.9,\n",
            " 'beta2': 0.95,\n",
            " 'datasets': [['pile', None, None, None]],\n",
            " 'embed_dropout': 0,\n",
            " 'eos_id': 50256,\n",
            " 'epsilon': 1e-08,\n",
            " 'eval_batch_size': 128,\n",
            " 'eval_steps': 0,\n",
            " 'gradient_clipping': 1.0,\n",
            " 'iterations': 500,\n",
            " 'layout': 'intermediate_expanded:x,heads:x,memory_length:y,embd:y',\n",
            " 'lr': 0.0002,\n",
            " 'lr_decay': 'cosine',\n",
            " 'lr_decay_end': 300000,\n",
            " 'mesh_shape': 'x:4,y:2',\n",
            " 'model_path': 'gs://test-bucket-neo/GPT3_XL',\n",
            " 'n_ctx': 2048,\n",
            " 'n_embd': 2048,\n",
            " 'n_head': 16,\n",
            " 'n_layer': 24,\n",
            " 'n_vocab': 50257,\n",
            " 'opt_name': 'adam',\n",
            " 'padding_id': 50257,\n",
            " 'precision': 'bfloat16',\n",
            " 'predict_batch_size': 128,\n",
            " 'predict_steps': 0,\n",
            " 'recompute_grad': True,\n",
            " 'res_dropout': 0,\n",
            " 'scale_by_depth': True,\n",
            " 'scale_by_in': False,\n",
            " 'tokens_per_mb_per_replica': 4096,\n",
            " 'train_batch_size': 16,\n",
            " 'train_steps': 363000,\n",
            " 'warmup_steps': 3000,\n",
            " 'weight_decay': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPwwbPCA6O7r"
      },
      "source": [
        "# Begin Fine-Tuning\n",
        "\n",
        "If you are fine-tuning the pretrained model, this line of code will begin the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YlaHzyXuMaj"
      },
      "source": [
        "!python3 main.py --model $pretrained_model --steps_per_checkpoint $steps_per_checkpoint --tpu colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_HxtEmBGTGT"
      },
      "source": [
        "## Sample from your model\n",
        "\n",
        "Once training is finished, you can run the same command with the --predict flag to sample from your model.\n",
        "\n",
        "To pass in a prompt, save it to a .txt file, and pass in the name of the file with the --prompt flag.\n",
        "\n",
        "use the cell below to enter your prompt, and run it to save it to example_prompt.txt.\n",
        "\n",
        "You may need to decrease the predict batch size in your config if you're facing OOM errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQE1Y5wPFx7h"
      },
      "source": [
        "%%writefile example_prompt.txt\n",
        "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
        "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
        "researchers was the fact that the unicorns spoke perfect English."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf_5E4fHFQIh",
        "outputId": "1ff75682-733a-4bdf-f907-8a59342f0b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 main.py --model $pretrained_model --steps_per_checkpoint 500 --tpu colab --predict --prompt example_prompt.txt"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-22 10:08:31.001931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Current step 362000\n",
            "Saving config to gs://test-bucket-neo/GPT3_XL\n",
            "2021-03-22 10:08:39.935638: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-22 10:08:39.938064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-22 10:08:39.951123: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-22 10:08:39.951189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c302fa39312d): /proc/driver/nvidia/version does not exist\n",
            "2021-03-22 10:08:40.663454: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
            "Done!\n",
            "params = defaultdict(<function fetch_model_params.<locals>.<lambda> at 0x7fb41de743b0>, {'n_head': 16, 'n_vocab': 50257, 'embed_dropout': 0, 'lr': 0.0002, 'lr_decay': 'cosine', 'warmup_steps': 3000, 'beta1': 0.9, 'beta2': 0.95, 'epsilon': 1e-08, 'opt_name': 'adam', 'weight_decay': 0, 'train_batch_size': 16, 'attn_dropout': 0, 'train_steps': 363000, 'lr_decay_end': 300000, 'eval_steps': 0, 'predict_steps': 0, 'res_dropout': 0, 'eval_batch_size': 128, 'predict_batch_size': 8, 'iterations': 500, 'n_embd': 2048, 'datasets': [['pile', None, None, None]], 'model_path': 'gs://test-bucket-neo/GPT3_XL', 'n_ctx': 2048, 'n_layer': 24, 'scale_by_depth': True, 'scale_by_in': False, 'attention_types': ['global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local', 'global', 'local'], 'mesh_shape': 'x:4,y:2', 'layout': 'intermediate_expanded:x,heads:x,memory_length:y,embd:y', 'activation_function': 'gelu', 'recompute_grad': True, 'gradient_clipping': 1.0, 'tokens_per_mb_per_replica': 4096, 'precision': 'bfloat16', 'padding_id': 50257, 'eos_id': 50256, 'dataset_configs': {'pile': {'n_vocab': 50257, 'path': 'gs://neo-datasets/pile/pile_*.tfrecords', 'eval_path': 'gs://neo-datasets/pile_val.tfrecords', 'tokenizer_is_pretrained': True, 'tokenizer_path': 'gpt2', 'eos_id': 50256, 'padding_id': 50257}}, 'mlm_training': False, 'causal': True, 'num_cores': 8, 'auto_layout': False, 'auto_layout_and_mesh_shape': False, 'use_tpu': True, 'gpu_ids': ['device:GPU:0'], 'steps_per_checkpoint': 500, 'predict': True, 'model': 'GPT', 'export': False, 'sampling_use_entmax': False, 'moe_layers': None, 'slow_sampling': False})\n",
            "Using config: {'_model_dir': 'gs://test-bucket-neo/GPT3_XL', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.61.149.242:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.61.149.242:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.61.149.242:8470', '_evaluation_master': 'grpc://10.61.149.242:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=8, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fb41de79a50>}\n",
            "_TPUContext: eval_on_tpu True\n",
            "Predictions generated\n",
            "Querying Tensorflow master (grpc://10.61.149.242:8470) for TPU system metadata.\n",
            "2021-03-22 10:08:45.739633: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:373] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "Initializing TPU system (master: grpc://10.61.149.242:8470) to fetch topology for model parallelism. This might take a while.\n",
            "Found TPU system:\n",
            "*** Num TPU Cores: 8\n",
            "*** Num TPU Workers: 1\n",
            "*** Num TPU Cores Per Worker: 8\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -6856062885122167732)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3039875018352825902)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 220810973976151207)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7090634611909330614)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -6748299067354506635)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5522360823467377999)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8687872666462328727)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7975278636740043433)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8608669260862027171)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1145189288048478292)\n",
            "*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7553479727321341645)\n",
            "Calling model_fn.\n",
            "num_cores_per_replica: 1\n",
            "computation_shape: [1, 1, 1, 1]\n",
            "num_replicas: 8\n",
            "device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "2021-03-22 10:08:53.530584: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "device_list = ['/job:worker/task:0/device:CPU:0']\n",
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "SimdMeshImpl init: Shape[x=4, y=2] LayoutRules{('intermediate_expanded', 'x'), ('embd', 'y'), ('memory_length', 'y'), ('heads', 'x')}\n",
            "Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fb41a09f210>\n",
            "Create pnum_tensor\n",
            "Variable gpt2/h0/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h0/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h0/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h0/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h0/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h0/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h1/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h1/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h1/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h1/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h1/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h1/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h10/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h10/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h10/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h10/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h10/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h10/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h11/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h11/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h11/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h11/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h11/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h11/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h12/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h12/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h12/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h12/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h12/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h12/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h13/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h13/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h13/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h13/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h13/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h13/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h14/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h14/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h14/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h14/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h14/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h14/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h15/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h15/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h15/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h15/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h15/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h15/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h16/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h16/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h16/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h16/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h16/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h16/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h17/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h17/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h17/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h17/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h17/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h17/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h18/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h18/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h18/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h18/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h18/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h18/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h19/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h19/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h19/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h19/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h19/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h19/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h2/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h2/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h2/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h2/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h2/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h2/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h20/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h20/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h20/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h20/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h20/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h20/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h21/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h21/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h21/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h21/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h21/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h21/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h22/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h22/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h22/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h22/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h22/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h22/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h23/attn/k                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h23/attn/o                                              size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h23/attn/q                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h23/attn/v                                              size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h23/mlp/conv1d_main/c_fc/kernel                         size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h23/mlp/conv1d_main/c_proj/kernel                       size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h3/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h3/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h3/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h3/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h3/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h3/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h4/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h4/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h4/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h4/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h4/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h4/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h5/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h5/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h5/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h5/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h5/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h5/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h6/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h6/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h6/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h6/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h6/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h6/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h7/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h7/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h7/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h7/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h7/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h7/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h8/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h8/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h8/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h8/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h8/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h8/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/h9/attn/k                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h9/attn/o                                               size 4194304      slice_size 524288       Shape[heads=2048, embd=2048]                                \n",
            "Variable gpt2/h9/attn/q                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h9/attn/v                                               size 4194304      slice_size 524288       Shape[embd=2048, heads=2048]                                \n",
            "Variable gpt2/h9/mlp/conv1d_main/c_fc/kernel                          size 16777216     slice_size 2097152      Shape[embd=2048, intermediate_expanded=8192]                \n",
            "Variable gpt2/h9/mlp/conv1d_main/c_proj/kernel                        size 16777216     slice_size 2097152      Shape[intermediate_expanded=8192, embd=2048]                \n",
            "Variable gpt2/wpe                                                     size 4194304      slice_size 2097152      Shape[embed_sequence=2048, embd=2048]                       \n",
            "Variable gpt2/wte                                                     size 102926336    slice_size 51463168     Shape[vocab=50257, embd=2048]                               \n",
            "Variable stacked/gpt2/h0/mlp/conv1d_main/c_fc/bias                    size 196608       slice_size 49152        Shape[stacked=24, intermediate_expanded=8192]               \n",
            "    gpt2/h0/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h1/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h2/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h3/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h4/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h5/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h6/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h7/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h8/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h9/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h10/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h11/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h12/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h13/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h14/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h15/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h16/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h17/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h18/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h19/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h20/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h21/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h22/mlp/conv1d_main/c_fc/bias\n",
            "    gpt2/h23/mlp/conv1d_main/c_fc/bias\n",
            "Variable stacked/gpt2/h0/norm_1/g                                     size 131072       slice_size 65536        Shape[stacked=64, embd=2048]                                \n",
            "    gpt2/h0/norm_1/g\n",
            "    gpt2/h0/norm_1/b\n",
            "    gpt2/h0/attn/compute_output_bias/o_b\n",
            "    gpt2/h0/norm_2/g\n",
            "    gpt2/h0/norm_2/b\n",
            "    gpt2/h0/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h1/norm_1/g\n",
            "    gpt2/h1/norm_1/b\n",
            "    gpt2/h1/attn/compute_output_bias/o_b\n",
            "    gpt2/h1/norm_2/g\n",
            "    gpt2/h1/norm_2/b\n",
            "    gpt2/h1/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h2/norm_1/g\n",
            "    gpt2/h2/norm_1/b\n",
            "    gpt2/h2/attn/compute_output_bias/o_b\n",
            "    gpt2/h2/norm_2/g\n",
            "    gpt2/h2/norm_2/b\n",
            "    gpt2/h2/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h3/norm_1/g\n",
            "    gpt2/h3/norm_1/b\n",
            "    gpt2/h3/attn/compute_output_bias/o_b\n",
            "    gpt2/h3/norm_2/g\n",
            "    gpt2/h3/norm_2/b\n",
            "    gpt2/h3/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h4/norm_1/g\n",
            "    gpt2/h4/norm_1/b\n",
            "    gpt2/h4/attn/compute_output_bias/o_b\n",
            "    gpt2/h4/norm_2/g\n",
            "    gpt2/h4/norm_2/b\n",
            "    gpt2/h4/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h5/norm_1/g\n",
            "    gpt2/h5/norm_1/b\n",
            "    gpt2/h5/attn/compute_output_bias/o_b\n",
            "    gpt2/h5/norm_2/g\n",
            "    gpt2/h5/norm_2/b\n",
            "    gpt2/h5/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h6/norm_1/g\n",
            "    gpt2/h6/norm_1/b\n",
            "    gpt2/h6/attn/compute_output_bias/o_b\n",
            "    gpt2/h6/norm_2/g\n",
            "    gpt2/h6/norm_2/b\n",
            "    gpt2/h6/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h7/norm_1/g\n",
            "    gpt2/h7/norm_1/b\n",
            "    gpt2/h7/attn/compute_output_bias/o_b\n",
            "    gpt2/h7/norm_2/g\n",
            "    gpt2/h7/norm_2/b\n",
            "    gpt2/h7/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h8/norm_1/g\n",
            "    gpt2/h8/norm_1/b\n",
            "    gpt2/h8/attn/compute_output_bias/o_b\n",
            "    gpt2/h8/norm_2/g\n",
            "    gpt2/h8/norm_2/b\n",
            "    gpt2/h8/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h9/norm_1/g\n",
            "    gpt2/h9/norm_1/b\n",
            "    gpt2/h9/attn/compute_output_bias/o_b\n",
            "    gpt2/h9/norm_2/g\n",
            "    gpt2/h9/norm_2/b\n",
            "    gpt2/h9/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h10/norm_1/g\n",
            "    gpt2/h10/norm_1/b\n",
            "    gpt2/h10/attn/compute_output_bias/o_b\n",
            "    gpt2/h10/norm_2/g\n",
            "Variable stacked/gpt2/h10/norm_2/b                                    size 131072       slice_size 65536        Shape[stacked=64, embd=2048]                                \n",
            "    gpt2/h10/norm_2/b\n",
            "    gpt2/h10/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h11/norm_1/g\n",
            "    gpt2/h11/norm_1/b\n",
            "    gpt2/h11/attn/compute_output_bias/o_b\n",
            "    gpt2/h11/norm_2/g\n",
            "    gpt2/h11/norm_2/b\n",
            "    gpt2/h11/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h12/norm_1/g\n",
            "    gpt2/h12/norm_1/b\n",
            "    gpt2/h12/attn/compute_output_bias/o_b\n",
            "    gpt2/h12/norm_2/g\n",
            "    gpt2/h12/norm_2/b\n",
            "    gpt2/h12/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h13/norm_1/g\n",
            "    gpt2/h13/norm_1/b\n",
            "    gpt2/h13/attn/compute_output_bias/o_b\n",
            "    gpt2/h13/norm_2/g\n",
            "    gpt2/h13/norm_2/b\n",
            "    gpt2/h13/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h14/norm_1/g\n",
            "    gpt2/h14/norm_1/b\n",
            "    gpt2/h14/attn/compute_output_bias/o_b\n",
            "    gpt2/h14/norm_2/g\n",
            "    gpt2/h14/norm_2/b\n",
            "    gpt2/h14/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h15/norm_1/g\n",
            "    gpt2/h15/norm_1/b\n",
            "    gpt2/h15/attn/compute_output_bias/o_b\n",
            "    gpt2/h15/norm_2/g\n",
            "    gpt2/h15/norm_2/b\n",
            "    gpt2/h15/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h16/norm_1/g\n",
            "    gpt2/h16/norm_1/b\n",
            "    gpt2/h16/attn/compute_output_bias/o_b\n",
            "    gpt2/h16/norm_2/g\n",
            "    gpt2/h16/norm_2/b\n",
            "    gpt2/h16/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h17/norm_1/g\n",
            "    gpt2/h17/norm_1/b\n",
            "    gpt2/h17/attn/compute_output_bias/o_b\n",
            "    gpt2/h17/norm_2/g\n",
            "    gpt2/h17/norm_2/b\n",
            "    gpt2/h17/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h18/norm_1/g\n",
            "    gpt2/h18/norm_1/b\n",
            "    gpt2/h18/attn/compute_output_bias/o_b\n",
            "    gpt2/h18/norm_2/g\n",
            "    gpt2/h18/norm_2/b\n",
            "    gpt2/h18/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h19/norm_1/g\n",
            "    gpt2/h19/norm_1/b\n",
            "    gpt2/h19/attn/compute_output_bias/o_b\n",
            "    gpt2/h19/norm_2/g\n",
            "    gpt2/h19/norm_2/b\n",
            "    gpt2/h19/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h20/norm_1/g\n",
            "    gpt2/h20/norm_1/b\n",
            "    gpt2/h20/attn/compute_output_bias/o_b\n",
            "    gpt2/h20/norm_2/g\n",
            "    gpt2/h20/norm_2/b\n",
            "    gpt2/h20/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h21/norm_1/g\n",
            "    gpt2/h21/norm_1/b\n",
            "Variable stacked/gpt2/h21/attn/compute_output_bias/o_b                size 36864        slice_size 18432        Shape[stacked=18, embd=2048]                                \n",
            "    gpt2/h21/attn/compute_output_bias/o_b\n",
            "    gpt2/h21/norm_2/g\n",
            "    gpt2/h21/norm_2/b\n",
            "    gpt2/h21/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h22/norm_1/g\n",
            "    gpt2/h22/norm_1/b\n",
            "    gpt2/h22/attn/compute_output_bias/o_b\n",
            "    gpt2/h22/norm_2/g\n",
            "    gpt2/h22/norm_2/b\n",
            "    gpt2/h22/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/h23/norm_1/g\n",
            "    gpt2/h23/norm_1/b\n",
            "    gpt2/h23/attn/compute_output_bias/o_b\n",
            "    gpt2/h23/norm_2/g\n",
            "    gpt2/h23/norm_2/b\n",
            "    gpt2/h23/mlp/conv1d_main/c_proj/bias\n",
            "    gpt2/ln_f/g\n",
            "    gpt2/ln_f/b\n",
            "Trainable Variables            count: 150     Total size: 1315575808       Total slice_size: 204753920      \n",
            "All Variables                  count: 150     Total size: 1315575808       Total slice_size: 204753920      \n",
            "Counters:\n",
            "allreduce: 2.02e+10\n",
            " allreduce/[0]: 6.45e+09\n",
            "  allreduce/[0]/einsum_op: 6.45e+09\n",
            " allreduce/[1]: 1.37e+10\n",
            "  allreduce/[1]/einsum_op: 1.37e+10\n",
            "  allreduce/[1]/reduce_op: 2.54e+07\n",
            "einsum: 3.67e+13\n",
            "einsum_unique: 2.57e+13\n",
            "output: 2.65e+11\n",
            " output/AddOperation: 6.82e+10\n",
            " output/BinaryOpWithBroadcasting: 5.2e+08\n",
            " output/BroadcastOperation: 6.48e+09\n",
            " output/ConcatOperation: 3.22e+09\n",
            " output/Constant: 1.97e+05\n",
            " output/EinsumOperation: 6.98e+10\n",
            " output/ImportOperation: 2.62e+05\n",
            " output/OneHotOperation: 6.62e+09\n",
            " output/RangeOperation: 2.54e+05\n",
            " output/ReduceOperation: 3.8e+07\n",
            " output/ReshapeOperation: 1.21e+10\n",
            " output/ScalarAddOperation: 6.45e+09\n",
            " output/ScalarMultiplyOperation: 2.27e+10\n",
            " output/ShiftOperation: 1.61e+09\n",
            " output/SlicewiseOperation: 5.24e+10\n",
            " output/StackedVariable: 1.59e+06\n",
            " output/StopGradient: 9.66e+09\n",
            " output/UnstackOperation: 1.59e+06\n",
            " output/Variable: 1.64e+09\n",
            " output/WhileLoopOperation: 3.22e+09\n",
            "output_unique: 1.46e+11\n",
            " output_unique/AddOperation: 3.72e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 6.72e+07\n",
            " output_unique/BroadcastOperation: 6.45e+09\n",
            " output_unique/ConcatOperation: 1.61e+09\n",
            " output_unique/Constant: 2.46e+04\n",
            " output_unique/EinsumOperation: 3.07e+10\n",
            " output_unique/ImportOperation: 3.28e+04\n",
            " output_unique/OneHotOperation: 8.28e+08\n",
            " output_unique/RangeOperation: 3.28e+04\n",
            " output_unique/ReduceOperation: 1.42e+07\n",
            " output_unique/ReshapeOperation: 6.44e+09\n",
            " output_unique/ScalarAddOperation: 3.22e+09\n",
            " output_unique/ScalarMultiplyOperation: 1.05e+10\n",
            " output_unique/ShiftOperation: 8.05e+08\n",
            " output_unique/SlicewiseOperation: 3.75e+10\n",
            " output_unique/StackedVariable: 4.96e+05\n",
            " output_unique/StopGradient: 8.05e+09\n",
            " output_unique/UnstackOperation: 4.96e+05\n",
            " output_unique/Variable: 1.32e+09\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 1.32e+09\n",
            " variables/trainable: 1.32e+09\n",
            "Done calling model_fn.\n",
            "TPU job name worker\n",
            "Graph was finalized.\n",
            "Restoring parameters from gs://test-bucket-neo/GPT3_XL/model.ckpt-362000\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:840: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "Starting infeed thread controller.\n",
            "Starting outfeed thread controller.\n",
            "Initialized dataset iterators in 0 seconds\n",
            "Before copy master to slices.\n",
            "Done with copy master to slices.\n",
            "Enqueue next (1) batch(es) of data to infeed.\n",
            "Dequeue next (1) batch(es) of data from outfeed.\n",
            "Outfeed finished for iteration (0, 0)\n",
            "======================================== SAMPLE 0 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "The findings are detailed in the newly published paper, \"Out of the Straight Trees:\n",
            "Identifying Unicorns in Theed Regolith,” in the journal Geodiversity.\n",
            "\n",
            "“In a lot of respects, the story of the Unicorns in the Andes is less than\n",
            "exciting,” said senior author Hubei Sin, a Martinosian scientist at Shanghai Jiao Tong\n",
            "University and associated researcher at the Nature Conservancy. “We’ve never seen\n",
            "one in the wild and only at the lab.”\n",
            "\n",
            "The study found a population of about 10 unicorns living in a remote region of\n",
            "the highland plateau in Peru. The valley has been little explored and there were no\n",
            "reports of unicorns around it until four men and one woman ventured there in August,\n",
            "2009. At that time five unicorns were living there, and the researchers could not\n",
            "tell how many of those individuals were females. At least some of the animals were\n",
            "already old, meaning they were probably in their prime.\n",
            "\n",
            "The population of the Unicorns remained there for two years and began to grow in\n",
            "2010. In 2011, the researchers had to travel further down the valley to interview\n",
            "more of the people who resided there and found a population of 14 unicorns. Another\n",
            "two unicorns emerged in 2012 and in 2013 another three. In 2013 and 2014, when the\n",
            "typical sign of a unicorn showed up, four to five individuals emerged. In 2014 the\n",
            "number grew to 11—the most in five years and the most in a single year since 2004.\n",
            "At that point, the researchers were beginning to learn considerably more about the\n",
            "unicorns, but were still unaware of the presence of wild domestic horses and their\n",
            "ancestors.\n",
            "\n",
            "The surprising finding also included the fact that the unicorns had perfect,\n",
            "unbroken English speech. Most other animals that are known to mate with humans do\n",
            "not actually use language—the animals that do are usually described as “silent\n",
            "spectators.” That means while they may be able to hear, they don’t actually talk.\n",
            "\n",
            "Study team members warned the team of this fact well in advance so that the team\n",
            "wouldn’t be completely surprised by the results. Sin detailed the team's reasoning\n",
            "in the paper.\n",
            "\n",
            "In Amore, the team, led by Ms. Sin, found that the unicorns spoke perfect English\n",
            "when they turned into them. Andrea Fortunato, also a senior team member, told the\n",
            "Wall Street Journal that while the team still didn't understand why this was so, there\n",
            "were \"some large telltale signs that supported this. When a unicorn turns into a\n",
            "unicorn, the hairs fall off its body as its wings split. It is not hard to see why\n",
            "something so'strange' would have these cryptic markings.\"\n",
            "\n",
            "The team also went to great lengths to match the local language to the language the\n",
            "unicorns spoke as well as to match the national ones. They found that both the\n",
            "national and the local languages were spoken by regions in the valley called the\n",
            "Andes.\n",
            "\n",
            "But the researchers found one very interesting digression from the national\n",
            "language. In the Andes, there is a group of people called “o puertos del monte”\n",
            "(the windows of the mountain), or the Andean group, which are descendants of\n",
            "ancestors who lived at the top of the Andes mountains. The researchers associated the\n",
            "unicorns with the o puertos del monte, which became a reference to the mountain in\n",
            "the region.\n",
            "\n",
            "There are several estimates of the population density of the unicorns, so the\n",
            "study was unable to account for the exact number of animals in the population.\n",
            "However, the researchers estimated that the population was between 5 and 10. Having\n",
            "a population of 10 suggests the population was kept relatively small by the unicorns\n",
            "living in the Andes, although that does not qualify as \"a liveable population.\" But\n",
            "that doesn’t account for unicorns living there forever.\n",
            "\n",
            "Now that the researchers had reached that conclusion, it was time to figure out just\n",
            "where the unicorns lived. “I got on a plane to Peru and flew to the Andes to see\n",
            "the unicorns and also to visit the o puertos del monte,” said Fortunato. “They are a\n",
            "very steep valley and it is really difficult to see much over, but I was there. When\n",
            "we arrived, I was able to drive with a guide down the valley by following signs.”\n",
            "\n",
            "The researchers also encountered a herd of people in the valley who could tell them\n",
            "when the unicorns were near based on the way they moved. “When they got in, the\n",
            "unicorns were gone. I knew they were close enough to see them, so I made the most\n",
            "of that,\" said Fortunato. The researchers also found a trail they could follow to\n",
            "travel towards the Andes.\n",
            "\n",
            "As the unicorns began to grow in the party's camp, Fortunato and his team learned\n",
            "that the track was not straight. “It ended on a slight downhill slope. The tops of\n",
            "the mountains were higher than the valley floor. At the end of the path, there was\n",
            "a slope on the opposite side of the valley with a steep hill to climb. That’s when\n",
            "we discovered that the trail was not straight,” said Fortunato.\n",
            "\n",
            "They found this on the way down. “The upper slopes are flat, but once we got down\n",
            "they began to slope upwards and everyone was scared. We stayed on the path for a\n",
            "while and then began to look for another way to get down. We found a little ‘pizza\n",
            "shop’ near a stream, where we took a pizza and garden salad to go [but no unicorns were\n",
            "in there],” said Fortunato. “We did find some unicorns but none of them were mobile.\n",
            "A little later, when we turned back to the chamber and we began to talk to the\n",
            "unicorns again, we found that they were located around the other side of the\n",
            "valley.”\n",
            "\n",
            "So the next question was what the unicorns were talking about. “A little after\n",
            "that we had our first conversation,” said Fortunato. Many interviews were held, and\n",
            "this is what they heardunicorns speaking in Andean and Quechua, but it was not\n",
            "the same as speech.\n",
            "\n",
            "In 2008, the researchers found a population of another species of mythical unicorn\n",
            "living in the area. “We found an old flightless unicorn with wings, that survived\n",
            "by eating the leaves of the neighboring valleys. The flightless unicorn has the\n",
            "same bull like eyes as the flightless horses, so we thought that only one could be\n",
            "the unicorn that I had seen,” said Fortunato. But it turned out it was actually two\n",
            "unicorns with different characteristics. One had the eyes and the other ones the\n",
            "ears. The ears had no hair and were rather long. Two sphinx-like figures that were\n",
            "met with the nearby wanderer group. “The unicorn that was supposed to be the one\n",
            "with the long ears had hair on its ears, but the other one had hair on all of its\n",
            "ears,” said Fortunato.\n",
            "\n",
            "Now, as they began to visit the o puertos del monte, it became clear that these\n",
            "people were their ancestors. “The o puertos del monte are our relatives, and\n",
            "they’re really much like us,” said Fortunato. “They’re proud of their reputation\n",
            "for being ‘the keepers of the mountain’ and are quite insistent on proving it.\n",
            "But they also claim that they are far from civilisation,” said Fortunato. “Back in\n",
            "times when the o puertos del monte were the keepers of the mountain, they said it\n",
            "was a lot more difficult to get down than it is now.”\n",
            "\n",
            "When the team started to visit they realized that the mountain was much higher\n",
            "than usual. It was about 7,000 feet. And that was where the unicorns were—lo and\n",
            "behold, there were 5 to 10 of them. “We had to climb over the mountain. When we\n",
            "came near the unicorns, we found a small valley on the other side,” said senior\n",
            "team member Carl Cohen, a researcher at the University of York.”\n",
            "\n",
            "“It was interesting to find no humans up and down the mountains. We think this\n",
            "is a fragmented population, and we can’t be quite sure. It’s very hard to learn\n",
            "much about these animals because of the paucity of references we find in literature,”\n",
            "said Fortunato.\n",
            "\n",
            "Oxford Ancient History notes that the original inhabitants of the high Andes\n",
            "around 5,000 years ago were a group of people called the Hill Fountains. The\n",
            "hill-fountains are also called the Andes or indigenous peoples of the high Andes.\n",
            "\n",
            "“The researchers studied the rock art of the thousands of original temples\n",
            "they discovered. The ancient sites, which were preserved due to their isolation\n",
            "from other sites, are some of the most spectacular examples of culture that have\n",
            "survive. Unlike\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "“It was so amazing,\" said Dr. Ruth Chrisman, one of the authors of the study. \"The\n",
            "unicorns, who can be heard throughout the valley, spoke perfectly in the\n",
            "English they were native to.\"\n",
            "\n",
            "Several previous studies have identified the existence of unicorns in the Andes\n",
            "Mountains, but no one before Dr. Chrisman’s team had ever suspected the unicorns\n",
            "were there. Unicorns have been known to live in valleys in the Andes in other\n",
            "regions, but these places are nearly an hour’s hike from the mountain range, so this\n",
            "was a surprise.\n",
            "\n",
            "“We see them here in almost no one’s backyard,” Dr. Chrisman said. “We can\n",
            "explore these valleys for many years and never really see any of them by nature.”\n",
            "\n",
            "The researchers were optimistic that the unicorns would eventually be discovered by\n",
            "students and researchers.\n",
            "\n",
            "“We don’t know where these unicorns come from,” Dr. Chrisman said. “All we know is\n",
            "they are basically one day of the living dinosaurs. It’s a big deal for them.”\n",
            "\n",
            "However, there are still many unanswered questions.\n",
            "\n",
            "Dr. Chrisman explained that the animals will need to be protected from predators\n",
            "to survive. Unicorns have little lungs, so they need to breathe by the mouth via a\n",
            "hole in the top of their head. One of the theories surrounding the discovery is that a\n",
            "large animal spilled seed into the valley, discouraging wildlife and likely preventing\n",
            "unicorns from reaching a higher breeding population.\n",
            "\n",
            "“Prey animals can have a big impact on the population of existing predators,” Dr.\n",
            "Chrisman said. “If a predator is too big and too strong, it is much harder for it\n",
            "to survive. The animals are finding the people on the other side of the mountain\n",
            "better off than they would in the valley.”\n",
            "\n",
            "The scientists are hoping to uncover more information on the formation of the\n",
            "valley. For example, what is the species of the desert? Are ecological pressures\n",
            "defining the current landscape?\n",
            "\n",
            "A second team of researchers, Dr. John Davey and Dr. Steven Martello, recently\n",
            "published a study that identifies a large population of snakes in the same valley.\n",
            "The experimental results, coupled with the limited natural presence of unicorns,\n",
            "suggests that snakes and unicorns could be directly linked.\n",
            "\n",
            "“This shows that species in the same habitat aren’t completely independent,” Dr.\n",
            "Davey said. “They belong to the same guild, are interacting.”\n",
            "\n",
            "Although Dr. Chrisman and Dr. Martello are already planning to sample more and more\n",
            "vales, they are still hopeful that they will be able to discover the unicorns in\n",
            "their search.\n",
            "\n",
            "“We’re really looking forward to the next single day,” Dr. Chrisman said. “We will\n",
            "go to the end of the valley and see if we can see any of these unicorns.”\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 2 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "In 2003, the owners of a farm where they could raise goats, llamas, and utallah, the alpacas, discovered a herd of over a hundred gold-colored beasts\n",
            "lying some 3,500 feet below the ground. This was just over the border of their\n",
            "country of origin, in the highlands of Peru, where the alpaca's original colored\n",
            "plastron was not recognized as an authentic gold color. No one could tell the\n",
            "alpaca from the llama with the naked eye, so the Chinese alpaca herd was removed.\n",
            "Later, it was discovered that the alpaca appeared to nearly all of the women to\n",
            "be full-fledged farmers. And that was entirely correct! For scientists were able\n",
            "to describe the alpaca years ago as having seven successful pregnancies out of\n",
            "seven females born, all of which were females.\n",
            "\n",
            "Researchers discovered the elusive unicorns during a very exhaustive search\n",
            "of the mountains that cover the highlands of Peru. They began by cutting down\n",
            "birch trees and removing those that sported gold leaves. Then they uprooted the\n",
            "tall trees and used a metal saw to break them down into little chunks weighing a\n",
            "few tons each, each of which they buried about 10,000 feet underground.\n",
            "\n",
            "Having all of the alpaca's tails and tooth root, the researchers are now\n",
            "obtaining a huge stash of a huge variety of gold, silver, and copper, and several\n",
            "bits of gold, silver, and copper jewelry, as well as many other precious metals,\n",
            "curiosities, and seed-bearing plants from the alpaca's mountain meadows. The alpaca\n",
            "cultivators seem to have turned into even more of a gold digging, insect eating,\n",
            "bird eating, dog eating, and horse eating machine than the herd of the alpacas,\n",
            "for they unwittingly used 559 different plant species as fertilizers in their\n",
            "friskiest efforts at replenishing the alpaca's countless nutrients.\n",
            "\n",
            "The owners of this fertility cult, who believe the alpaca's fertility has\n",
            "a fertilizing effect on the sheep and cattle, plan to return to the highlands of\n",
            "Peru with a small pack of pack hounds, who they hope will mate with the alpaca\n",
            "herd's many young unicorns. So far they seem to be successful in keeping the\n",
            "unicorns in their proper places.\n",
            "\n",
            "The next phase of the alpaca fertility cult is to attract and separate the\n",
            "unicorns from the rest of the herd. The question is how far and deep the drop\n",
            "dart can be drawn. Will it only reach the greens of the alpaca's\n",
            "mountain meadows? Can big grasses be safely cut down with a metal saw? And what\n",
            "help are we getting from the alpaca herders' own livestock?\n",
            "\n",
            "The alpacas were fed three hundred pounds of plant material every two days,\n",
            "with the plants taking the form of small sticks, tied together by twine. Every\n",
            "two days they would eat one small plant. Plants that were less than 3 inches in\n",
            "diameter and those that were more than 3 inches in size were broken apart and\n",
            "stuffed into theleses. As the Kenyan alpaca population ages, so must the herd.\n",
            "And so will the herd be when it reaches 40,000 years of age!\n",
            "\n",
            "The alpacas are too away from their original home in the highlands, south of\n",
            "the Andes mountains in Peru, to be shepherded by the Chinese who claimed to be\n",
            "brought up hunting and gathering the alpaca's eggs, as did some Tibetan\n",
            "artisans! That claim was immediately denied by the Tlingit Indians who inhabit\n",
            "a little country above the Andes mountains, and who say they are not carried\n",
            "away to hunt for the alpaca.\n",
            "\n",
            "The alpaca's numbers are certainly too low for anything but a slow genetic\n",
            "replacement by the endless stream of alpaca's progeny that will grow up in the\n",
            "mountains, as the Chinese alpaca herd erode and die. And the alpacas will eat\n",
            "the alpaca grass for years into the future. But what about the unicorns? Will\n",
            "they continue to grow?\n",
            "\n",
            "Scientists are thinking not only about keeping the unicorns in their high\n",
            "mountain meadows, but also about making sure they will disperse as soon as\n",
            "possible. Here in the SE-US region of my two adopted states of Oregon and Idaho\n",
            "we have a unicorns renaissance going on, and we are very much looking forward\n",
            "to the arrival of the later part of their lives in the mountains in the coming\n",
            "years. We hope that the alpacas will come and help as well, just as the two\n",
            "arid vegetation groups that share this same desert habitat, the Uplands and\n",
            "Desert, help, enabling the alpacas and other natives to interact harmoniously.\n",
            "\n",
            "Sometime in the next twelve to eighteen months the alpacas will vanish. The\n",
            "unicorns will breed and multiply and assume new forms, like the ridged blade\n",
            "of a reentrant ocean wave surfacing at a moment's notice, like the great gust\n",
            "of wind at dusk that sweeps over the desert plains. And so will the alpacas, for\n",
            "they will return to the highland mountains where they first sprang from and in\n",
            "the coming years will usher in the biological and cultural migrations of the\n",
            "unicorns into the highlands, along with the alpacas.\n",
            "\n",
            "If they do not breed and multiply again within the seventy five years\n",
            "they will leave the highland mountains and come down into the E-West to the\n",
            "mountains. It is to be hoped that their vast herds of seven-year-old unicorns\n",
            "have spread far and wide and there are few alpaca herds left in the highlands,\n",
            "for the plains of America's shallow green are disappearing and there are no\n",
            "alpacas left in the highlands, challenged by the alpaca herders.\n",
            "\n",
            "That is the stage I envision our vanishing alpacas being faced with: the\n",
            "non-breeding alpacas, put to flight by the alpaca herders and the endless\n",
            "copulations of the alpaca's numerous progeny that will follow their evolutionary\n",
            "architecture. Is it likely that any of the alpacas will manage to return, and\n",
            "what would they need to do to return the alpacas to their proper territory in\n",
            "the highland mountains, as their progeny have done in the E-West?\n",
            "\n",
            "It is difficult to predict just how high the alpacas will become after they\n",
            "leave the mountains. I imagine yet another enormous exodus over the next few\n",
            "years of the alpacas, for they will run wild in every state. And it is likely\n",
            "that most alpacas will go to the highlands, given the height of the\n",
            "mountain-dwelling alpaca herds, as they did in India and China. And it is\n",
            "possible that many of the alpacas of the Himalayas, or even the highlands of\n",
            "the landscape of Tibet, will stay in their high mountain habitats, just as the\n",
            "kings of China have done for millennia. Tibet and China are the two biggest\n",
            "places in the world that have alpaca herds and are ruled by alpaca herdsmen. As\n",
            "far as I can recall there are only two other places, one that is in the\n",
            "Pacific coast of India, and one in central China, where even the Chinese alpaca\n",
            "herders have been officially exiled. I only know this from my brief knowledge\n",
            "of the facts based on what I have seen in these mountains and in the E-West.\n",
            "\n",
            "But where have the alpacas gone? I cannot say where they were ever gone\n",
            "before. They disappear into the Himalayas every year like the alpacas with\n",
            "twenty thousand young unicorns on their hands, but where are they now? There is\n",
            "no highland city where I know them. Perhaps they are hiding somewhere like\n",
            "Saskatchewan, Canada, or in a cold rain forest. This is the one place where\n",
            "they will never be seen again, like the end of the world. The alpacas of the\n",
            "Himalayas, Tibet, or Central China will never return here, at least not in their\n",
            "real form.\n",
            "\n",
            "**The sun is setting in the Southwestern U.S. again this evening, but we\n",
            "will have no way of knowing whether alpacas will be here first, second or both\n",
            "times.**\n",
            "\n",
            "A GUTTERING WIPE MELTS OFF THE MELTING SUN. THIS IS GREAT! GOOD TO KNOW\n",
            "THAT.\n",
            "\n",
            "**We have found not one, but five alpaca herds in the highlands of Peru.**\n",
            "\n",
            "**The highland alpaca herd is no more than an estimated 100\n",
            "thousand animals.**\n",
            "\n",
            "**The last alpaca herd was in the Huasamus valley in\n",
            "the highlands of Peru.**\n",
            "\n",
            "**They are some of the last of a long line of herds that have\n",
            "evolved from the alpaca that crossed the Andes mountains in Peru and\n",
            "spread to the highlands of the great nation of Peru.**\n",
            "\n",
            "**The alpacas of Peru are most likely descended from the alpacas\n",
            "that crossed the Andes mountains in Peru and spread to the highlands of Peru.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 3 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English. “They’re\n",
            "almost like Capri,” said Christiaan van der Waart from the single largest study of\n",
            "unicorns to date. “They live around a great lake known as Lake Umatilla, in a\n",
            "land more than 6,000 feet (2,000 meters) high. And it’s perfect for the\n",
            "unicorns!”\n",
            "\n",
            "The researchers were studying the large herd of unicorns at the\n",
            "Field Museum in Chicago, which in the past few years has turned its attention to\n",
            "the fertile fields of Brazil and to unicorns from around the world. (See a\n",
            "summary of the unicorns from the Field Museum.) In this new research, van der\n",
            "Waart and fellow researchers, Onno Kopp, Ph.D., advisor of the North Dakota Unicorns\n",
            "Conservation Office, and Ji Yi, Ph.D., a curator at the Field Museum, discovered\n",
            "that the unicorns were the product of a mating pattern that has been passed\n",
            "down in a community of various species. The researchers then carefully studied\n",
            "the specimens, hoping to find out more about the mating process and the\n",
            "unicorns’ other secrets. Following their work, the team published in Science the\n",
            "following discoveries:\n",
            "\n",
            "1. The sexual habits of the unicorns are pretty\n",
            "tight and regular. There’s not much out there that the researchers can’t\n",
            "study.\n",
            "\n",
            "2. The unicorn foal is born, a young fawn, with\n",
            "four legs and a hump. The original unicorn foal grew to about 2 ½ feet (1\n",
            "meter) tall. Some juveniles can grow up to at least 6 feet (1.8 meters) and some\n",
            "up to 8 feet (2.5 meters).\n",
            "\n",
            "3. The herds of unicorns are divided into\n",
            "thirds: the first third sexually mature females, the second third as revealed by\n",
            "their blowholes and skulls, the last third mostly males. That last third\n",
            "makes up just about half of the whole herd.\n",
            "\n",
            "4. All males and females are good breeders. The\n",
            "unicorns tend to fight only amongst themselves. The cows, all males, form\n",
            "stable herds even if there are fights between bulls. The bulls fight amongst\n",
            "themselves when they reach maturity, and the fighting males head for\n",
            "different herds.\n",
            "\n",
            "5. The clear rule of mating for a unicorn is\n",
            "that the male and female must mate in the same herd.\n",
            "\n",
            "6. Unicorns are monogamous herd animals. They\n",
            "don’t form groups of more than three.\n",
            "\n",
            "7. Unicorns live in herds that are\n",
            "small.\n",
            "\n",
            "8. Curiously, the herdings of unicorns come\n",
            "down to three major valleys in the Andes Mountains: one in the Eldorado Basin,\n",
            "the second in the Espiritu Santo Basin, and the third in the Lake Umatilla\n",
            "Basin.\n",
            "\n",
            "9. The dinosaurs were not nearly as\n",
            "important to the life of the unicorns as they were to the early humans, a\n",
            "contrast the team finds startling. Modern humans are the only living species that\n",
            "has emerged on the Earth with the same grouping of species.\n",
            "\n",
            "10. Its all in the males, with smaller women,\n",
            "unlike the females of modern humans or the prehistoric horses, which are\n",
            "large, with many females.\n",
            "\n",
            "The experts themselves are somewhat surprised by\n",
            "the finding. “I was under the impression that\n",
            "unicorns were in a love triangle,” said van der Waart. “That they seemed\n",
            "unaffected.”\n",
            "\n",
            "The team then asked the question: “So do the\n",
            "unicorns not know there are other species in their herd?”\n",
            "\n",
            "“No, of course not!” responded van der Waart.\n",
            "“But if they do that, which would be much, much more\n",
            "stressful they should be.”\n",
            "\n",
            "The scientists studied some of the\n",
            "unicorns’ DNA. By studying a couple of\n",
            "unicorns, they could isolate the genes.\n",
            "\n",
            "The scientists then go to work on some rare\n",
            "unicorns that have been collected in Brazil’s reserve\n",
            "wildlife sites. Using the DNA samples they\n",
            "collected, they undertake genetic studies to determine whether there are any\n",
            "other species in the Andes.\n",
            "\n",
            "This is such an exciting scientific find. And the\n",
            "NewsWeek review on the NSF confirmed that the team is undoubtedly on to something.\n",
            "\n",
            "“Since 1996, Dr van der Waart has gone on to\n",
            "study and control the herds of unicorns throughout the world. He has\n",
            "documented the complete natural and reproductive lives and characteristics of 88\n",
            "unicorn herds, among them the rareest, smallest, and largest. He has described and\n",
            "surveyed their home range, ranges of movement and altitude, and genetic\n",
            "characteristics, including mitochondrial DNA. His study of the genetic structure\n",
            "shows the isolatedness of the herds, with precise regional distributions of\n",
            "distinct populations.\n",
            "\n",
            "“His expertise and many years of fieldwork\n",
            "have prepared him to focus on searching local, regional, and global\n",
            "ecosystems in order to develop comprehensive conservation programs for\n",
            "unicorns. In the context of conservation, his work now focuses on\n",
            "introducing a unique management plan for the North American and\n",
            "Sub-Saharan Unicorn ‘Home Range’. He joins a growing number of\n",
            "scientists and conservationists in the United States and abroad who are identifying\n",
            "and preserving the world’s remaining wild unicorns. He is also involved with\n",
            "the Pacta Florale Foundation ‘unicorns for\n",
            "youth’ project that is trying to reintroduce modern-day unicorns into Finland.\n",
            "\n",
            "His work has, in a parallel, national and\n",
            "global context, raised the profile of the vulnerable and charismatic\n",
            "unicorns – wild bulls that can have their horns crushed or broken by\n",
            "horned predators and even a rarer group of small, almost undetectable\n",
            "unicorns, that live in small, inconspicuous tufts of grass in\n",
            "narrow canyons.\n",
            "\n",
            "“These gentlemen are the great explorers…\n",
            "and they may know more about wild bulls than even the top\n",
            "international ornithologists.”\n",
            "\n",
            "Dr. Christiaan van der Waart, the\n",
            "unprecedented study of the wild unicorns of Bolivia\n",
            "\n",
            "There’s one area that the NSF is talking about\n",
            "regarding the NSF related work. We may have uncovered some facts that\n",
            "are related to the unicorns.\n",
            "\n",
            "One of those is in the past. We’ve been\n",
            "following this story in the media for a while now. About a year ago,\n",
            "Scott Patterson, a conservation biologist and the current director of\n",
            "Wildlife Services in the Forest Service Service’s\n",
            "Mt. St. Helens Program, interviewed Dr. Christiaan\n",
            "van der Waart, using a video produced by Wilder Prairie\n",
            "Day Tracking, which is a conservation non-profit dedicated to\n",
            "rescuing the rarest and most endangered species in the country.\n",
            "\n",
            "Scot says that idea of an endangered\n",
            "unicorn, which is a genetically different species from its\n",
            "congeners, was provocative and allowed the people\n",
            "who’s rural and isolated existence in the Andes Mountains to really get\n",
            "excited. Scot said that is why when the information was presented,\n",
            "people were so excited.\n",
            "\n",
            "“But it wasn’t until they went ‘Look at\n",
            "This!’ that people were actually or are starting to realize there is a real\n",
            "problem out there.”\n",
            "\n",
            "Well, that’s been the case, at least. And\n",
            "what this study accomplishes and speaks to is that rare unicorns are\n",
            "mostly, or even often, found in isolated areas. The team determined that\n",
            "unicorns don’t migrate much. In fact, the researchers say, they are the\n",
            "only herd of migrating unicorns.\n",
            "\n",
            "And so, this is the study that has really been\n",
            "certainly the most exciting investigation done so far. Before this study,\n",
            "there was a lot more to see and learn about at the Field Museum’s and\n",
            "Maccabee Glacier and similar locations around the world.\n",
            "\n",
            "The Unicorns: A love triangle, but not a lot of information on the future of the unicorn. The field museum seems to know all about the beast.\n",
            "\n",
            "If you would like to be notified when we post a main description, you can subscribe to our blog feed. We only post to this blog once a day, so it’s easy to get your email. Just click on the follow button. Have a blessed day!\n",
            "\n",
            "You’d think the NSF would just check the unicorns on this blog first. From the comments on Scott’s Wake Up Show-Interview\n",
            ", where he discusses the report of the NSF related work on the\n",
            "unicorns:\n",
            "\n",
            "“As a wildlife biologist, you’re acutely aware\n",
            "that wildlife conservation is not a matter of ‘experts’ or\n",
            "‘doctors,’ or whatever. It’s a matter of people doing\n",
            "something.”\n",
            "\n",
            "AVK: “And we happen to be attorneys,\n",
            "immersed in money and law. None of that matters to us. Now,\n",
            "speaking in the broadest terms, presumably an educated person with a\n",
            "scientific mindset takes great care in studying the habits of these\n",
            "wonder\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 4 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "The most incredible finding of Ariely's team was their\n",
            "discovery of what they call a \"support crew of a socialized society.\" That paranormal\n",
            "elaborate species of animals not unlike unicorns that evolved in the rainforests\n",
            "of South America before being reintroduced to the Andes.\n",
            "\n",
            "There are many questions that have yet to be answered about the actual situation of these\n",
            "equine herders.\n",
            "\n",
            "Andersson the Director of the Institute of Big Data Management of the University of Turku University in Finland seems to have\n",
            "reached some frustrated conclusions about the possible resident eels as well.\n",
            "\n",
            "\"It's very well known that the\n",
            "lands were rarely used for grazing before the move to the Amazon forest, that the\n",
            "grasslands provide an adequate environment for wildlife just by themselves,\n",
            "regardless of the existence of a grazing land,\" Andersson said. \"But the\n",
            "connection between the two is as yet unknown, as well.\"\n",
            "\n",
            "\"The swampy places where the supposedly group\n",
            "referred equine herders lived are some of the most difficult places in the\n",
            "Andes to trek through in full sunlight with a dead horse,\" Andersson said. \"It\n",
            "may be there that they have developed the,\" Andersson said with a smile, \"the\n",
            "perfect instant communication.\"\n",
            "\n",
            "It all started last year with a plan for a survey of the area. From the beginning they have\n",
            "had some success.\n",
            "\n",
            "An observer who monitored the area for the\n",
            "forestro GPS told the researchers this month that the area was\n",
            "\n",
            "\"at record-high\" levels, but there had\n",
            "also been some \"shooting stars\" every few months.\n",
            "\n",
            "But the orange parrots, the desert foxes and the\n",
            "solitary pilot damselflies are being by far the most novel and impressive living things in the area.\n",
            "\n",
            "Andersson would have to be pleased with that.\n",
            "\n",
            "\"All this area covered\n",
            "in a few years has not been used for grazing before,\" he said. \"All the\n",
            "significant habitat in the Andes is used very intensively for agriculture and\n",
            "timber production and there is already a lot of pressure to create habitat if not\n",
            "for wildlife and then for livestock.\"\n",
            "\n",
            "\"The green\n",
            "\n",
            "\n",
            "\n",
            "teams now at work, revitalizing the area in\n",
            "ways they never dreamed possible and helping to protect the remaining, irreplaceable\n",
            "wildlife we've talked about before, or has already done.\"\n",
            "\n",
            "According to\n",
            "\n",
            "Andersson, zebra, colobus monkey and an Amazon civet came to the area\n",
            "partially because it was the \"wildest valley in the region.\"\n",
            "\n",
            "A species of\n",
            "\n",
            "the extinct Eocene period, the\n",
            "\n",
            "audinos mjaelpsavirustuun is\n",
            "\n",
            "known to be a very social species living in small groups of up to two,\n",
            "where they communicate telepathically using just their bellies like\n",
            "\n",
            "one of their own species.\n",
            "\n",
            "Despite being one of the most peaceful\n",
            "\n",
            "animals ever discovered, according to\n",
            "\n",
            "Andersson, \"audino's have never been\n",
            "left to exist, they have been forced out of the valley and they can't find any\n",
            "previous habitat.\n",
            "\n",
            "\"One of the reasons\n",
            "they are still around is because they are not aggressive; they wouldn't even\n",
            "shoot at the people who are killing their habitat,\" Andersson said.\n",
            "\n",
            "\"They have not been hunted since they\n",
            "started\n",
            "\n",
            "living in the valley,\" he added. \"They\n",
            "might have some disease that affects them, but they would never uproot. They\n",
            "are not aggressive and they do not fight with the people who are trying to take\n",
            "their habitat.\n",
            "\n",
            "\"They are\n",
            "\n",
            "watchful; they are not fighting with each other like eagles, these are\n",
            "friendly montane\n",
            "\n",
            "hunting parrots,\" Andersson said. \"They\n",
            "leave all the danger to the people who want to have something that reminds of\n",
            "them and not something else.\"\n",
            "\n",
            "That\n",
            "\n",
            "audino's of the Rain forest compart the\n",
            "\n",
            "circumstance of being able to live in a valley\n",
            "\n",
            "without human interference, which Andersson\n",
            "\n",
            "found to be \"answers for many of the\n",
            "questions we asked.\"\n",
            "\n",
            "The research team also interviewed some\n",
            "\n",
            "of the local elders who said they had heard many a story\n",
            "\n",
            "about the bottlenose dolphins, a group that\n",
            "\n",
            "not only can talk to each other but are non-aggressive and make \"bad\n",
            "\n",
            "decisions\" when it comes to hunting and\n",
            "\n",
            "killing animals, making them very much like\n",
            "\n",
            "their own species.\n",
            "\n",
            "The experts\n",
            "\n",
            "would like to see a new ecosystem with no wildlife, but animals doing well and\n",
            "being well cared for under a proper, environmental management system.\n",
            "\n",
            "To that end, the researchers created a clever\n",
            "\n",
            "computer model that tries to describe the environment of the area to see how the\n",
            "Andean ecosystem looks like.\n",
            "\n",
            "Based on the scale, the computer\n",
            "\n",
            "simulates areas where humans are present, called \"urban and semi urban areas,\"\n",
            "or \"open water areas, or open space.\"\n",
            "\n",
            "What\n",
            "\n",
            "they find is that indeed there are some areas with a lot of open space,\n",
            "\n",
            "where the animals are able to exist as they are\n",
            "\n",
            "and some areas where they sit out in the sun for doing the more mundane\n",
            "\n",
            "things, which are mentioned elsewhere on this website.\n",
            "\n",
            "\"It brings into the\n",
            "\n",
            "equestrian landscape the idea of a sufficient environment to survive, use\n",
            "and thrive without human intervention,\" Andersson said. \"It is a\n",
            "\n",
            "necessary goal to try to achieve.\"\n",
            "\n",
            "The animal species they sampled spoken English, which means Andersson used some\n",
            "\n",
            "of the most current and most promising emerging technologies to\n",
            "\n",
            "implement a sophisticated language communication device.\n",
            "\n",
            "Andersson and colleagues were able to\n",
            "\n",
            "implement a neural network machine-learning\n",
            "\n",
            "model that speaks search commands stored in a database with millions of\n",
            "\n",
            "words, which translates to most of these animals' current movement patterns.\n",
            "\n",
            "\"The entire\n",
            "\n",
            "maps these people are recording and\n",
            "\n",
            "processing are electronic maps of\n",
            "\n",
            "the entire Andean forest ecosystem,\"\n",
            "\n",
            "Andersson said. \"The initial\n",
            "\n",
            "plans for the project were to do a\n",
            "\n",
            "large scale study and it took 10\n",
            "\n",
            "years and lots of money but it ended up\n",
            "\n",
            "being the most successful thing we\n",
            "\n",
            "have been able to do in terms of\n",
            "\n",
            "providing\n",
            "\n",
            "physical\n",
            "\n",
            "evidence\n",
            "\n",
            "for\n",
            "\n",
            "the\n",
            "\n",
            "and\n",
            "\n",
            "autonomy\n",
            "\n",
            "of equine presence in the Andean\n",
            "\n",
            "ecosystem.\"\n",
            "\n",
            "Andersson seemed to think he came up\n",
            "\n",
            "with a wonderful concept.\n",
            "\n",
            "A\n",
            "\n",
            "collection of an international team,\n",
            "\n",
            "he decided to undertake an experiment\n",
            "\n",
            "where he enlisted some speech therapy\n",
            "\n",
            "experts to help him develop a\n",
            "\n",
            "real-life mother-son\n",
            "son speech communication system\n",
            "\n",
            "that would help these spectacular\n",
            "\n",
            "animals communicate with one another in\n",
            "\n",
            "a linguistic, interactive format.\n",
            "\n",
            "The researchers hope to translate\n",
            "\n",
            "the next versions of their approach to\n",
            "\n",
            "an arsenal of technologies in the near\n",
            "\n",
            "future.\n",
            "\n",
            "It's just like the warm-up in the\n",
            "\n",
            "obviously more advanced video and\n",
            "\n",
            "photography competitions where\n",
            "\n",
            "you can set up situations and\n",
            "\n",
            "the results are usually amazing.\n",
            "\n",
            "The team is excited that they have\n",
            "\n",
            "created a real possibility\n",
            "\n",
            "of understanding how these animals are\n",
            "\n",
            "thinking in their natural habitat and\n",
            "\n",
            "training a new generation of animal\n",
            "\n",
            "specialists in their natural environment.\n",
            "\n",
            "The unicorn\n",
            "\n",
            "documented human presence in\n",
            "\n",
            "Andean\n",
            "\n",
            "ecosystems\n",
            "\n",
            "allows scientists to\n",
            "\n",
            "find\n",
            "\n",
            "scenarios\n",
            "\n",
            "to\n",
            "\n",
            "study\n",
            "\n",
            "how\n",
            "\n",
            "these animals act and react\n",
            "\n",
            "to human presence.\n",
            "\n",
            "The\n",
            "\n",
            "unicorns are a remarkable\n",
            "\n",
            "example of\n",
            "\n",
            "the most innovative communication\n",
            "\n",
            "mechanisms ever discovered.\n",
            "\n",
            "Their\n",
            "\n",
            "voice\n",
            "\n",
            "is\n",
            "\n",
            "ideally programmed, programmed to\n",
            "\n",
            "express anything they feel they feel\n",
            "\n",
            "or want to say.\n",
            "\n",
            "They can\n",
            "\n",
            "speak\n",
            "\n",
            "without duress\n",
            "\n",
            "and\n",
            "\n",
            "without needing to make a decision\n",
            "\n",
            "or any\n",
            "\n",
            "verbal\n",
            "\n",
            "communication.\n",
            "\n",
            "They have a\n",
            "\n",
            "complex\n",
            "\n",
            "brain that can perceive, process\n",
            "\n",
            "and\n",
            "\n",
            "translate human body language into\n",
            "\n",
            "their own language.\n",
            "\n",
            "They communicate\n",
            "\n",
            "about physical\n",
            "\n",
            "situations through a\n",
            "\n",
            "series of\n",
            "\n",
            "gestures and\n",
            "\n",
            "movements.\n",
            "\n",
            "Or\n",
            "\n",
            "to\n",
            "\n",
            "speak\n",
            "\n",
            "a\n",
            "\n",
            "complete\n",
            "\n",
            "language journey\n",
            "\n",
            "into the experiences they have about\n",
            "\n",
            "all possible situations in life.\n",
            "\n",
            "The study of\n",
            "\n",
            "unicorns is opening a huge\n",
            "\n",
            "and interesting new\n",
            "\n",
            "regional\n",
            "\n",
            "possibilities for human\n",
            "\n",
            "reflected\n",
            "\n",
            "scientific work.\n",
            "\n",
            "This\n",
            "\n",
            "does not\n",
            "\n",
            "mean\n",
            "\n",
            "they are evil, these are\n",
            "\n",
            "animals\n",
            "\n",
            "that are very intelligent and are\n",
            "\n",
            "capable of\n",
            "\n",
            "working\n",
            "\n",
            "together.\n",
            "\n",
            "But they are very social\n",
            "\n",
            "and\n",
            "\n",
            "they have to keep\n",
            "\n",
            "company\n",
            "\n",
            "with\n",
            "\n",
            "other\n",
            "\n",
            "unicorns\n",
            "\n",
            "that have been going from\n",
            "\n",
            "solitary and\n",
            "\n",
            "fast\n",
            "\n",
            "to\n",
            "\n",
            "grouped.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 5 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "It wasn’t the first time these amazing creatures have been discovered, but it’s the first time they stick\n",
            "to the forest floor. They may be a completely new species to science, but as long\n",
            "as the scientists continue studying them, they’ll be called “unicorns”.\n",
            "\n",
            "The “unicorns” had, of course, been a safe haven for creatures the hardest to make out of the Amazon rainforest.\n",
            "When they were through exploring they’d retreat to a point that the trail took too\n",
            "draggy for them to reach. Then they’d keep going and trying to get to a new point,\n",
            "but never find another trail. The scientists called this “the valley of the unicorns”.\n",
            "\n",
            "As controversy continues to surround the efforts to re-examine the area, the\n",
            "unicorns have finally made their way back to the forest floor. They’ve evolved there,\n",
            "but not as well as they would have in the jungle. So it’s a good thing the scientists\n",
            "managed to find them the first time.\n",
            "\n",
            "The researchers think they’re singing the world a day’s notice about the research they’re doing in the Andes Mountains. The unicorns have also announced their interest in their new home, and they’re pledging allegiance to France.\n",
            "\n",
            "As the technology and the scientific world examines this mystery, a group of adrenaline-addicted researchers have settled upon the conclusion that this mystery should be great.\n",
            "\n",
            "The problem was that it was too easy. It was just a bunch of beetles or some other damn thing that just crawled its way up there. But that was all that was necessary for the scientists to be excited.\n",
            "\n",
            "As I stated earlier, these creatures are more than a hundred years away from being declared a new species. It’s only our most skilled specialists that can develop much of a science. Scientists who had done tiny amounts of research before striking out on their own, or ones that were afraid to go after such a big project, like the unicorns.\n",
            "\n",
            "If the scientists don’t find the unicorns soon, it will open more doors to classified species, and even large ones. Well, at least for the researchers.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 6 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English. The researchers\n",
            "described this discovery as a \"lost dinosaur of the Andes.\"\n",
            "\n",
            "The discovery was made in a cave in the national park of Yuraldo, in the\n",
            "southern part of Peru.\n",
            "\n",
            "Around 19,000 years ago, the earthquakes of the initial Ice Age, along with\n",
            "the end of the Peruvian highlands, and the spread of glaciers across the\n",
            "region, caused the ancient Andes Mountains to contract and shrink into a\n",
            "series of smaller mountain ranges. The smaller range was the tallest, and\n",
            "the scientists believe there may have been a relatively small population of\n",
            "unicorns living in the valleys before this point.\n",
            "\n",
            "But in two separate areas, the scientists discovered a herd of unicorns\n",
            "living in a valley, which they identified as the site of a petrified\n",
            "forest. The researchers believe this population was the smallest of the\n",
            "touched, wild unicorns ever discovered.\n",
            "\n",
            "These plants were left as fossils by the animals, and some of these plants\n",
            "were being carried along on the wind as the animals were climbing up from\n",
            "the ground and leaving the area.\n",
            "\n",
            "\"The rock itself is hard, and it was\n",
            "very good and we had to cut these rocks with diamond drills,\" said Andor\n",
            "Carlsen, a researcher on the expedition. Andor Carlsen is an expert in\n",
            "tracking the deformation of stone, known as petrography, by a high-energy\n",
            "beam or laser. He is a professor in the Department of Earth, Atmospheric and\n",
            " Planetary Sciences at the University of Colorado, Boulder.\n",
            "\n",
            "Andor Carlsen (Image credit: Andor Carlsen)\n",
            "\n",
            "Andor Carlsen, a researcher on the expedition, described the discovery\n",
            "as a lost dinosaur of the Andes. He reassured those living in the area:\n",
            "\n",
            "\"We don't want to alarm anybody by listing the number of unicorns we've\n",
            "discovered, or perhaps by giving them the exact location of the\n",
            "petrified forest, because those rocks tell the story of the Andes through the\n",
            "formation of which they are made.\n",
            "\n",
            "\"We have to keep the differences in these two areas in mind, because if they\n",
            "were to disappear in the two areas listed, the potential of these\n",
            "researchers losing the first real evidence for our understanding of the\n",
            "greatest coming event that the Earth has ever experienced would be horrifying.\"\n",
            "\n",
            "The researchers hypothesize that the population of unicorns living in the\n",
            "valley may have been connected with the other dinosaur species, or with both\n",
            "species, but they also state, \"we cannot be sure what ancient remains we'd\n",
            "find if this two-way relationship were to exist, so we don't know whether\n",
            "these valley-dwelling extinct unicorns and other closely related\n",
            "dinosaur species represent a single, unified population, or a more\n",
            "complex compilation of a unique set of species.\"\n",
            "\n",
            "But Carlsen says, \"What would make the valley so unique is the\n",
            "differences it seems to have had in both the climate, both the amount and the\n",
            "places of the glaciers. And we know that volcanic activity, along with cold\n",
            "and rain, such as we've seen over the past 4000 years, tends to shrink areas\n",
            "that have been exposed to glaciation. So this valley was probably\n",
            "exposed to glaciers for a long time, and therefore perhaps the smaller the\n",
            "area the better.\"\n",
            "\n",
            "The scientists have since put together a research proposal to work with the\n",
            "permafrost through which the valley was exposed, to test out the hypothesis that\n",
            "this was the time when flows of methane gas may have first opened up the\n",
            "valley. The methane, which is a by-product of many types of plant life, is\n",
            "this study scientists predict would likely have had a negative effect on the\n",
            "valley.\n",
            "\n",
            "The discovery of the valley's petrified forest was led by Andor Carlsen and\n",
            "his team. The forest, which consisted of small, dead, green animals,\n",
            "wound up the 82 million year old sediment layer of Peruvian soil that covers the area.\n",
            "\n",
            "In this way, part of the ancient petrified forest was buried within Peruvian soil.\n",
            "In total, the researchers found, along with animal remains, more than 30,000\n",
            "small, fossilized petrified plant species.\n",
            "\n",
            "The researchers also wrote a paper about the findings with the support of the\n",
            "Environmental Protection Agency, which funds research on burial and other\n",
            "environmental sites, in the U.S.\n",
            "\n",
            "(Andor Carlsen is a professor in the Department of Earth, Atmospheric and\n",
            "Planetary Sciences at the University of Colorado, Boulder.)\n",
            "\n",
            "Source: University of Colorado News\n",
            "\n",
            "Top image: A team of scientists, led by University of Colorado at Boulder Professor\n",
            "Andor Carlsen, has discovered a petrified forest in Peru. Credit: University of Colorado.\n",
            "\n",
            "Explore further Scientists study petrified forest in ancient Peruvian sewer.\n",
            "\n",
            "More information:\n",
            "The paper: \"Petrified forest: Long-term petrographic study of a new petrified forest in a western lowland forest in the Andes, Peru\"\n",
            "\n",
            "No affiliation information.\n",
            "\n",
            "Source: University of Colorado News\n",
            "\n",
            "No potential conflict of interest was reported by the author(s).\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "======================================== SAMPLE 7 ========================================\n",
            "\n",
            "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
            "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
            "researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "The Pan American Archaeological Expedition which was jointly funded by\n",
            "the National Geographic Society and in part by the Smithsonian Institution,\n",
            "determined that the newly discovered valley, currently called \"Cosquer\" is\n",
            "home to a diverse, multi-ethnic group of prehistoric (between 50,000 B.C. and\n",
            "4000 B.C.E) human inhabitants, the first known community of which was an\n",
            "important center of social life.\n",
            "\n",
            "The newly discovered population numbers at least 300 individuals\n",
            "and is composed of three sub-groups: Xico (an indigenous Indian tribe, perhaps\n",
            "Cape Cervantes, Peru), Bokobenga (a Criollo tribe located along the Guatemalan\n",
            "border north of the city of Priego) and the indigenous Jibarana, which also\n",
            "prognosticated a very important part of the new valley's previous human\n",
            "prehistory.\n",
            "\n",
            "\"The discovery of these three groups are a clear example of\n",
            "the principles of prehistory in the Andes that we were just part of,\" said\n",
            "Dr. Juan Figueroa, Director of the Smithsonian Tropical Research Institute and\n",
            "Principal Investigator for the new Expedition. \"Human beings are a complex\n",
            "group of relatively recent and closely related species and we can only begin to\n",
            "understand the diversity and relationships of such a unique group of people by\n",
            "examining the people they left behind: the environment they left behind.\"\n",
            "\n",
            "The Jibarana, a member of what is often referred to as the Mayan civilization,\n",
            "were central to cosmogenetic models for the origin and development of human\n",
            "societies. As such, they were highly valued as frontiers of knowledge,\n",
            "especially as an important part of the cultural expansion of civilizations in\n",
            "Central America such as the Maya and Inca. At about 100 B.C.E, the Jibarana\n",
            "established an advanced village on a small location near the Guatemala-Peru\n",
            "border. Despite a long residence at the site, Jibarana archaeology is\n",
            "beginning to show evidence of a gradual human occupation from this site.\n",
            "\n",
            "Researchers have found evidence of buildings related to the culture\n",
            "of Jibaranas, but like the Jibarana remains they are being found on large\n",
            "sites. Their radiocarbon dates appear to be at least as far back as 200 B.C.E.\n",
            "\n",
            "However, a similar population has been noted on a remote valley in Eastern\n",
            "Peru as well. In this valley, called Cosquer, the new discovery represents a\n",
            "population of giant animals similar to the unicorns of North America. At about\n",
            "25 Km. long and 13 Km. wide, Cosquer is a beautiful valley with a suggestively\n",
            "low humidity. It is known as a hot-spot for diseases such as cholera,\n",
            "tuberculosis, and malaria.\n",
            "\n",
            "The Discovery\n",
            "\n",
            "Three years ago, a team of researchers led by Dr. Maria Villanueva of the\n",
            "National Geographic Society and Dr. Juan Figueroa, Director of the Smithsonian\n",
            "Tropical Research Institute, ventured to this remote desert canyon, where they\n",
            "discovered a population of primarily female, and male, unicorns. Thirteen species\n",
            "of unicorns exist in the Andes Mountains. The most famous is the male\n",
            "Ursus americanus. They are known as the tútara,\n",
            "a large, white-tipped animal with enormous horns, up to 18 meters long.\n",
            "\n",
            "The new spear-like tips of the female unicorns suggest that they\n",
            "were certainly able to defend themselves against predators from wild horses to\n",
            "predators from armed man-eaters.\n",
            "\n",
            "At about half the length of their horned counterparts, male unicorns\n",
            "are considerably smaller, having short, pointed tips. The deflective tips of\n",
            "the unicorns appear to are used for both self-defense and for as a means of\n",
            "hunting.\n",
            "\n",
            "The new species differs from companion species in that the males and\n",
            "female unicorns live in herds of up to 300 individuals, and dwarfs ranging from\n",
            "1.1 to 1.7 meters tall. Interestingly, over the past few generations, the\n",
            "bulls have not produced calves and instead have become more aggressive. Rather\n",
            "than tend to their mating pouters at home, they will defend their young against\n",
            "any aggressors in the herd. This behavior, we now know, has come about through a\n",
            "conversion of the bulls into violent and aggressive animals.\n",
            "\n",
            "Authentic Bone Remains Found\n",
            "\n",
            "The researchers collected a number of samples from the unicorns to\n",
            "determine a precise age range and gender classification. They also sought other\n",
            "samples for comparison with other genes. They performed lab tests to see if any\n",
            "of the samples contained the ABO blood type group, and some of the bones\n",
            "themselves were stained with diIodine (a radioactive substance to determine its\n",
            "proxies and predators) and Berlese-Palladium.\n",
            "\n",
            "The 12 samples which they collected all contained the ABO blood\n",
            "group. Two samples were not typed for this blood group and could not be\n",
            "determined to be definitively any blood group than the others., In addition,\n",
            "three of the samples contained bone fragments from the gizzards of bears of the\n",
            "meager size range (from 70-200 mg). While these samples have\n",
            "already been analyzed at Cornell University, the blood type analyzed in this\n",
            "study was the only one on record as being from a tútara (Tauris\n",
            "latrans, a separate subspecies).\n",
            "\n",
            "The bone fragments from the Unicorns were of the expected shape and\n",
            "size, and were of white or yellowish-yellow color, although an area of yellow\n",
            "could sometimes be seen. This yellowing may be caused by the animals themselves\n",
            "absorbing this bluish-yellow tincture that they release from their gizzards.\n",
            "\n",
            "The anal openings of the unicorns were also quite large and wide.\n",
            "Investigation showed that this was a feature common among the tútara. The size\n",
            "and shape of the anal openings suggests that the animals may have had\n",
            "bi-notations, in that they either entered the water at the surface or into\n",
            "the water following a river or stream. Animal behavior is impossible to predict,\n",
            "since that is a horse's version of life, so it is very likely that these animals\n",
            "were able to dive if necessary.\n",
            "\n",
            "As well, the anal openings of the unicorns are significantly\n",
            "smaller in diameter than other tútara bones found in the area. These\n",
            "sizes and treatment factors of tútara bones is consistent with the two\n",
            "different species of tútara that occur in the area. The unicorns appear to have\n",
            "had a similar diet since they do not contain ash (a substance thought to make\n",
            "their bones more resistant to decay) which is sometimes found among tútara\n",
            "bones.\n",
            "\n",
            "\"More\n",
            "surprising, the unicorns were not only able to bury their dead, they were also\n",
            "able to make figurines and jewelry from the ashes of their dead. This\n",
            "distribution suggests that the unicorns are a type of pre-domesticated animal,\"\n",
            "said Figueroa.\n",
            "\n",
            "A CONCLUSION\n",
            "\n",
            "The animal remains from the Cosquer geothermal basin have been\n",
            "preserved for at least five hundred years. \"TheImplications\n",
            "of this discovery are huge, and the value of this new expedition is staggering,\"\n",
            "said Figueroa. \"Not only were we able to document the existence of this\n",
            "large mammals, but they spoke the first known utterances of the\n",
            "incomprehensible language of the ancient past.\"\n",
            "\n",
            "A previous investigation of the Cosquer geothermal basin of the\n",
            "Andes Mountains, did not find a domesticated animal. \"The\n",
            "existing evidence is times with no basic explanation of how\n",
            "humans domesticated animals,\" said Figueroa. \"If this\n",
            "is not already explained by this expedition, our knowledge of the origin of\n",
            "humanity with all its great history would be much diminished.\"\n",
            "\n",
            "\"This new expedition provides a basis for the existence of\n",
            "animals that are not domesticated, and for the first time the\n",
            "equation of how humans domesticated animals can be validated,\"\n",
            "explained Figueroa. \"Does it appear that in this geothermal\n",
            "basin this time, the animal remains fall into two areas of discovery: the first\n",
            "naturalists of the area such as Father Jose, the Minatua Project researchers and\n",
            "authors and the second groups of researchers who are using the data of the\n",
            "preservation of the animal bones to put together an actual picture of\n",
            "the irresistible domestication of animals?\" asks Figueroa.\n",
            "\n",
            "The published results of the newly discovered petroglyphs include\n",
            "a detailed summary of the discoveries and a drawing depicting the appearance\n",
            "and use of the petroglyph sites during the most recent millennium.\n",
            "\n",
            "IN THE LIGHT OF CHOSEN UNIVERSES\n",
            "\n",
            "Such a discovery was a significant contribution to human\n",
            "development in the Andes Mountains and perhaps given the foundations needed for\n",
            "a new ten-point unifying curriculum for geology teachers.\n",
            "\n",
            "The\n",
            "UNICORN COSQUER consists of a number of petroglyphs which are wild animal\n",
            "earthen seals, the most common being the St. John's rose bull seal. The\n",
            "petroglyphs were found in caves and lagoons, and in high mountains in the vicinity\n",
            "of Cosquer.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Enqueue next (1) batch(es) of data to infeed.\n",
            "Dequeue next (1) batch(es) of data from outfeed.\n",
            "Outfeed finished for iteration (1, 0)\n",
            "Stop infeed thread controller\n",
            "Shutting down InfeedController thread.\n",
            "InfeedController received shutdown signal, stopping.\n",
            "Infeed thread finished, shutting down.\n",
            "infeed marked as finished\n",
            "Stop output thread controller\n",
            "Shutting down OutfeedController thread.\n",
            "OutfeedController received shutdown signal, stopping.\n",
            "Outfeed thread finished, shutting down.\n",
            "outfeed marked as finished\n",
            "Shutdown TPU system.\n",
            "prediction_loop marked as finished\n",
            "prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE9VImzHaI0z"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGGbkgaFfp6f"
      },
      "source": [
        "This section assumes you are using a pretrained model and relies on variables created in the `Pretrained model` section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I45yUIpbaLUJ"
      },
      "source": [
        "## Wikitext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwBDB9U2keFV"
      },
      "source": [
        "Download the wikitext test set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuugiBmJaNxf"
      },
      "source": [
        "wikitext103_src = \"https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\"\n",
        "!wget $wikitext103_src\n",
        "!unzip wikitext-103-raw-v1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5wf3QWKkhZt"
      },
      "source": [
        "Tokenize and upload to bucket:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mo8UUtDdctH"
      },
      "source": [
        "\n",
        "!mkdir wikitext\n",
        "!mv /content/GPTNeo/wikitext-103-raw/wiki.test.raw wikitext/wikitext_test.txt\n",
        "\n",
        "# Tokenize Data\n",
        "!python data/create_tfrecords.py --input_dir wikitext --name wikitext --files_per 1000 --output_dir wikitext_tokenized --write_dataset_config --processes 1 --wikitext-detokenize\n",
        "\n",
        "# copy the data to your bucket\n",
        "if not path_to_cloud_bucket.endswith('/'):\n",
        "  path_to_cloud_bucket += '/'\n",
        "copy_loc = path_to_cloud_bucket \n",
        "!gsutil -m cp -r wikitext_tokenized $copy_loc\n",
        "!gsutil ls $path_to_cloud_bucket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE84TUd1fAzf"
      },
      "source": [
        "Now make a dataset config that points to the tokenized wikitext data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5UU7DQeeY0S"
      },
      "source": [
        "%%writefile configs/dataset_configs/wikitext.json\n",
        "\n",
        "{\n",
        "  \"path\": \"\",\n",
        "  \"eval_path\": \"gs://test-bucket-neo/wikitext_tokenized/*.tfrecords\",\n",
        "  \"n_vocab\": 50256,\n",
        "  \"tokenizer_is_pretrained\": true,\n",
        "  \"tokenizer_path\": \"gpt2\",\n",
        "  \"eos_id\": 50256,\n",
        "  \"padding_id\": 50257\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egvdwIOqfFER"
      },
      "source": [
        "And update your model config to point to that dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "AtdoIFMgfOe8"
      },
      "source": [
        "# @title Modify config for wikitext. \n",
        "  \n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "batch_size = 8 #@param {type:\"integer\"}\n",
        "assert pretrained_model is not None\n",
        "with open(f'configs/{pretrained_model}.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "  pprint(data)\n",
        "  dset_val = [[\"wikitext\", None, None, None]]\n",
        "  mods = {\n",
        "          \"datasets\": dset_val,\n",
        "          \"eval_steps\": 139 // batch_size,\n",
        "          \"train_batch_size\": batch_size,\n",
        "          \"eval_batch_size\": batch_size,\n",
        "        }\n",
        "  data.update(mods)\n",
        "  print('\\n--->\\n')\n",
        "  pprint(data)\n",
        "  with open(f'configs/{pretrained_model}.json', 'w') as outfile:\n",
        "    json.dump(data, outfile, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2d5eTHEg6Xj"
      },
      "source": [
        "Now run model in eval mode over tokenized data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Uz3PXzg5Pm"
      },
      "source": [
        "!python3 main.py --eval --tpu colab --model $pretrained_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dbkPVcMhVaR"
      },
      "source": [
        "## Lambada\n",
        "\n",
        "Lambada eval is built into the codebase and can be run by adding a field to your model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "z4FJXOlJiEYo"
      },
      "source": [
        "# @title Modify config for Lambada. \n",
        "  \n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "batch_size = 8 #@param {type:\"integer\"}\n",
        "assert pretrained_model is not None\n",
        "with open(f'configs/{pretrained_model}.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "  mods = {\n",
        "          \"datasets\": dset_val,\n",
        "          \"eval_steps\": 0,\n",
        "          \"train_batch_size\": batch_size,\n",
        "          \"eval_batch_size\": batch_size,\n",
        "          \"eval_tasks\": [\"lambada\"]\n",
        "        }\n",
        "  data.update(mods)\n",
        "  print('\\n--->\\n')\n",
        "  pprint(data)\n",
        "  with open(f'configs/{pretrained_model}.json', 'w') as outfile:\n",
        "    json.dump(data, outfile, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upp-bGMriVPK"
      },
      "source": [
        "Now run the eval:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOA1YZDRiUhN"
      },
      "source": [
        "!python3 main.py --eval --tpu colab --model $pretrained_model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}