{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPTNeo_example_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0i5MRP0SV8D"
      },
      "source": [
        "Welcome to the colab notebook for [GPTNeo](https://github.com/EleutherAI/GPTNeo) - a fully open source implementation of GPT like models for mesh-tensorflow by [EleutherAI](eleuther.ai).\n",
        "\n",
        "Our library provides training and inference for GPT models up to GPT3 sizes on both TPUs and GPUs. \n",
        "\n",
        "In this notebook we walk you through TPU training (or finetuning!) and sampling using the freely available colab TPUs.\n",
        "\n",
        "If you find our repo useful, come join [our discord](https://discord.gg/BK2v3EJ) and say hi! ðŸ˜¬\n",
        "\n",
        "Before we get going - make sure you are running this notebook with a TPU available. Go to Runtime -> Change Runtime Type and select 'TPU' under hardware accelerator.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-53qkZV6Lv9",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5e37ba-4961-42c7-f07a-706e7ed81b40"
      },
      "source": [
        "#@title Setup\n",
        "%tensorflow_version 2.x\n",
        "!git clone https://github.com/EleutherAI/GPTNeo\n",
        "%cd GPTNeo\n",
        "!pip3 install -q -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GPTNeo'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 3567 (delta 37), reused 26 (delta 10), pack-reused 3485\u001b[K\n",
            "Receiving objects: 100% (3567/3567), 1.32 MiB | 2.18 MiB/s, done.\n",
            "Resolving deltas: 100% (2048/2048), done.\n",
            "/content/GPTNeo\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368kB 5.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.2MB 316kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 48.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 394.7MB 42kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.4MB 48.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 48.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 41.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 7.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184kB 41.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 44.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 52.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 50.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 8.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 56.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286kB 54.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.4MB/s \n",
            "\u001b[?25h  Building wheel for tpunicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wirerope (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: ortools 8.2.8710 has requirement absl-py>=0.11, but you'll have absl-py 0.10.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0R1owh2qvp8"
      },
      "source": [
        "## Set Google Cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PmzM4dy7diP"
      },
      "source": [
        "To train on TPUs we need to store our data on a google cloud bucket - as TPUs can't read from local filesystems.\n",
        "\n",
        "You can set up a bucket by signing up for a free trial here: https://console.cloud.google.com/\n",
        "\n",
        "Make a bucket at https://console.cloud.google.com/storage and come back when that's done.\n",
        "\n",
        "The next cell sets up google authentication and gives the notebook read and write access to your bucket.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bQUjPA7qvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bfd74e-7692-4e65-8334-63d76a84df74"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud init"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome! This command will take you through the configuration of gcloud.\n",
            "\n",
            "Settings from your current configuration [default] are:\n",
            "component_manager:\n",
            "  disable_update_check: 'True'\n",
            "compute:\n",
            "  gce_metadata_read_timeout_sec: '0'\n",
            "core:\n",
            "  account: stellabiderman@gmail.com\n",
            "\n",
            "Pick configuration to use:\n",
            " [1] Re-initialize this configuration [default] with new settings \n",
            " [2] Create a new configuration\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "Your current configuration has been set to: [default]\n",
            "\n",
            "You can skip diagnostics next time by using the following flag:\n",
            "  gcloud init --skip-diagnostics\n",
            "\n",
            "Network diagnostic detects and fixes local network connection issues.\n",
            "Reachability Check passed.\n",
            "Network diagnostic passed (1/1 checks passed).\n",
            "\n",
            "Choose the account you would like to use to perform operations for \n",
            "this configuration:\n",
            " [1] stellabiderman@gmail.com\n",
            " [2] Log in with a new account\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "You are logged in as: [stellabiderman@gmail.com].\n",
            "\n",
            "Pick cloud project to use: \n",
            " [1] chrome-orb-287416\n",
            " [2] Create a new project\n",
            "Please enter numeric choice or text value (must exactly match list \n",
            "item):  1\n",
            "\n",
            "Your current project has been set to: [chrome-orb-287416].\n",
            "\n",
            "Not setting default zone/region (this feature makes it easier to use\n",
            "[gcloud compute] by setting an appropriate default value for the\n",
            "--zone and --region flag).\n",
            "See https://cloud.google.com/compute/docs/gcloud-compute section on how to set\n",
            "default compute region and zone manually. If you would like [gcloud init] to be\n",
            "able to do this for you the next time you run it, make sure the\n",
            "Compute Engine API is enabled for your project on the\n",
            "https://console.developers.google.com/apis page.\n",
            "\n",
            "Your Google Cloud SDK is configured and ready to use!\n",
            "\n",
            "* Commands that require authentication will use stellabiderman@gmail.com by default\n",
            "* Commands will reference project `chrome-orb-287416` by default\n",
            "Run `gcloud help config` to learn how to change individual settings\n",
            "\n",
            "This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n",
            "Run `gcloud topic configurations` to learn more.\n",
            "\n",
            "Some things to try next:\n",
            "\n",
            "* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n",
            "* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr_c6A2NBK5i"
      },
      "source": [
        "path_to_cloud_bucket = 'gs://eleutherai' #@param {type:\"string\"}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZGbzUPD0tad"
      },
      "source": [
        "## Set Up Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R918l14UhrBR"
      },
      "source": [
        "We first need to download and tokenize a dataset - you can choose from:\n",
        "\n",
        "*   Sampling Only - choose this option if you only wish to sample from our trained models.\n",
        "\n",
        "*   OpenWebText - an opensource clone of OpenAI's WebText dataset, the original training data of GPT2.\n",
        "\n",
        "*   YoutubeSubtitles - a dataset of subtitles scraped from youtube videos.\n",
        "\n",
        "* Hackernews - comments scraped from hackernews\n",
        "\n",
        "* NIHExporter - Data relating to various projects from the national institute of health.\n",
        "\n",
        "* Custom - if this option is chosen you will be prompted to enter the path to your own dataset. It should be a directory containing .txt or .jsonl files.\n",
        "\n",
        "All these datasets are from EleutherAI's side project - [The Pileâ„¢](https://github.com/EleutherAI/The-Pile) - an effort to gather a general purpose, diverse and open source plain text dataset large enough to train 1T+ parameter language models.\n",
        "\n",
        "Even the smallest datasets are fairly large files, so this step will likely take a while. Select a dataset in the next cell, then run the next two cells, and go grab a snack and a cup of tea ðŸ˜Š\n",
        "\n",
        "Alternatively, you can provide your own dataset in the form of a folder or gzip archive of .txt files. Simply select 'Custom' below and follow input the path to your data and the name of your dataset when prompted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM8jP3Am_hsx",
        "cellView": "form"
      },
      "source": [
        "# Select a Dataset:\n",
        "import os\n",
        "dataset = 'Sampling_Only' #@param [\"Sampling_Only\", \"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom\"]\n",
        "\n",
        "if dataset == \"Sampling_Only\":\n",
        "  pass\n",
        "elif dataset == 'OpenWebText':\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar -O openwebtext.tar.xz\n",
        "  !tar xf openwebtext.tar.xz\n",
        "  dataset_path = \"openwebtext\"\n",
        "  dataset_name = dataset_path\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'YoutubeSubtitles':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/yt_subs.jsonl.zst -O data/yt_subs.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'ytsubs'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'HackerNews':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/hn.tar.gz -O data/hn.tar.gz\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'hackernews'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == \"NIHExporter\":\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/NIH_ExPORTER_awarded_grant_text.jsonl.zst -O data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  os.system('mv NIH_ExPORTER_awarded_grant_text.jsonl.zst ./data')\n",
        "  dataset_name = 'nihexporter'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == \"Custom\":\n",
        "  dataset_path = input('Enter the path to the folder containing your data: ')\n",
        "  dataset_name = input('Enter the name of your dataset: ')\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "else:\n",
        "  raise NotImplementedError('please select from available options: [\"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom\"]')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMl1cHtN5I_W"
      },
      "source": [
        "### Tokenize and Upload Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IBIompTJaqm"
      },
      "source": [
        "Now tokenize the dataset and copy it over to your google cloud bucket. You make skip this step if you are sampling from a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq5u0WUSJWwz",
        "cellView": "both"
      },
      "source": [
        "# Tokenize Data\n",
        "!python data/create_tfrecords.py --input_dir /content/GPTNeo/$dataset_path --name $dataset_name --files_per 1000 --output_dir $out_name --write_dataset_config --processes 1\n",
        "\n",
        "# copy the data to your bucket\n",
        "if not path_to_cloud_bucket.endswith('/'):\n",
        "  path_to_cloud_bucket += '/'\n",
        "copy_loc = path_to_cloud_bucket + \"datasets/\" + dataset\n",
        "!gsutil -m cp -r /content/GPTNeo/$out_name $copy_loc\n",
        "!gsutil ls $path_to_cloud_bucket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhvmTFD7b_fb"
      },
      "source": [
        "Before starting training - you'll need to edit your dataset & model configs to point to your buckets / data. You need to do this even if you are sampling from a pre-trained model.\n",
        "\n",
        "*   First change the writefile path to point to your chosen dataset - e.g `%%writefile configs/dataset_configs/ytsubs.json`\n",
        "*   Change the \"path\" field to point to your cloud bucket location - e.g `gs://neo_lmdatasets/datasets/ytsubs_*.tfrecords`\n",
        "* Change `dataset_name` in `%%writefile configs/dataset_configs/dataset_name.json` to the name of your chosen dataset.\n",
        "* Once you've made the edits, then run the cell below to overwrite the existing files.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCsZP48vavCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9490700d-5911-4d1e-f480-4e9f51ae7b01"
      },
      "source": [
        "%%writefile configs/dataset_configs/Sampling_Only.json\n",
        "\n",
        "{\n",
        "  \"path\": \"gs://eleutherai/datasets/Sampling_Only/Sampling_Only*.tfrecords\",\n",
        "  \"eval_path\": \"\",\n",
        "  \"n_vocab\": 50256,\n",
        "  \"tokenizer_is_pretrained\": true,\n",
        "  \"tokenizer_path\": \"gpt2\",\n",
        "  \"eos_id\": 50256,\n",
        "  \"padding_id\": 50257\n",
        "}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing configs/dataset_configs/Sampling_Only.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH0x3dI9j85P"
      },
      "source": [
        "## Set Model Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6GnCgAkB7GQ"
      },
      "source": [
        "The model below is identical to our pretrained GPT3XL model (1.3B Params). \n",
        "\n",
        "If you want to use a smaller model, you can modify any of the config files in ../configs/ ending in _8.json, all of which are designed to train on tpu-v8s.\n",
        "\n",
        "For a more detailed breakdown on what each item in the configuration file means - please read through our training and config guides in our [github README](https://github.com/EleutherAI/GPTNeo#training-guide). \n",
        "\n",
        "You'll want to change the first item in the `datasets` list to the name of your chosen dataset. (the filename minus .json in ./configs/dataset_configs)\n",
        "\n",
        "You'll also want to modify the `model_path` field to point to your google cloud bucket, so checkpoints get saved to there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9hUDdokiWj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dace4af-7da2-477e-c444-72237ccf9785"
      },
      "source": [
        "%%writefile configs/GPT3_XL.json\n",
        "\n",
        "{\n",
        "    \"n_head\": 16,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"embed_dropout\": 0,\n",
        "    \"lr\": 0.0002,\n",
        "    \"lr_decay\": \"cosine\",\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0,\n",
        "    \"train_batch_size\": 256,\n",
        "    \"attn_dropout\": 0,\n",
        "    \"train_steps\": 600000,\n",
        "    \"eval_steps\": 0,\n",
        "    \"predict_steps\": 1,\n",
        "    \"res_dropout\": 0,\n",
        "    \"eval_batch_size\": 4,\n",
        "    \"predict_batch_size\": 1,\n",
        "    \"iterations\": 100,\n",
        "    \"n_embd\": 2048,\n",
        "    \"datasets\": [[\"HackerNews\", null, null, null]],\n",
        "    \"model\": \"GPT\",\n",
        "    \"model_path\": \"gs://eleutherai/GPT3_XL\",\n",
        "    \"n_ctx\": 2048,\n",
        "    \"n_layer\": 24,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": false,\n",
        "    \"attention_types\" :  [[[\"global\", \"local\"],12]],\n",
        "    \"mesh_shape\": \"x:4,y:2\",\n",
        "    \"layout\": \"intermediate_expanded:x,heads:x,vocab:n_vocab,memory_length:y,embd:y\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"recompute_grad\": true,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"tokens_per_mb_per_replica\": 2048,\n",
        "    \"precision\": \"bfloat16\"\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing configs/GPT3_XL.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWK9MJqwcXKn"
      },
      "source": [
        "## Training from Scratch\n",
        "\n",
        "Now we will begin to train the model. If no previous model is found in \"model_path\", the model will start training from scratch. If you'd prefer to finetune from pretrained, skip to the `Finetune a Pretrained Model` section.\n",
        "\n",
        "If everything's set up correctly, you can now run the main.py function to start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUtrysOSBzjJ"
      },
      "source": [
        "!python3 main.py --model colab_XL --steps_per_checkpoint 500 --tpu colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koKQHA5ikCvD"
      },
      "source": [
        "## Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QZv4_pnkk26"
      },
      "source": [
        "If you want to sample from or finetune a pretrained model, EleutherAI has pretrained two models for release. One with [1.3B parameters](https://the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/), and another with [2.7B](https://the-eye.eu/eleuther_staging/gptneo-release/GPT3_2-7B/). \n",
        "\n",
        "Select an option below to download the weights locally. You will then need to upload them to your cloud bucket in order to finetune from them. If the download command isn't working, try the commented out code to download from a different source.\n",
        "\n",
        "The 2-7B model likely won't fit into the colab TPUs memory, and you may have to get some larger pods to finetune from it.\n",
        "\n",
        "Sampling from it, however, works just fine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgTG1ammqGB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "70a7ebec-cdae-4506-9a1a-b7c317cbf7e2"
      },
      "source": [
        "# @title Download pretrained model weights:\n",
        "pretrained_model = 'GPT3_XL' #@param [\"GPT3_XL\", \"GPT3_2-7B\"]\n",
        "\n",
        "!wget -m -np -c -U \"eye02\" -w 2 -R \"index.html*\" \"https://the-eye.eu/eleuther_staging/gptneo-release/$pretrained_model/\"\n",
        "path_to_local_weights = \"/content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/$pretrained_model\"\n",
        "\n",
        "# URL = f\"http://eaidata.bmk.sh/data/gptneo-release/{pretrained_model}/\"\n",
        "# FOLDER_NAME = \"GPT3_XL\"\n",
        "# !curl $URL | grep -i \"</a>\" | sed -n 's/.*href=\"\\([^\"]*\\).*/\\1/p' | sed \"s|^|$URL|\" | xargs -n 1 -P 4 wget -P $pretrained_model\n",
        "# path_to_local_weights = pretrained_model\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 03:32:03--  (try: 3)  https://the-eye.eu/robots.txt\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.242|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "Retrying.\n",
            "\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU3BDNJN_ZXE",
        "outputId": "eb11d681-578a-4114-8971-4d6983dc88c5"
      },
      "source": [
        "# upload to your bucket\n",
        "bucket_base = \"gs://\" + path_to_cloud_bucket.replace('gs://', '').split('/')[0]\n",
        "!gsutil -m cp -r $path_to_local_weights $bucket_base"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00020-of-00032 [Content-Type=application/octet-stream]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \rCopying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00001-of-00032 [Content-Type=application/octet-stream]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00000-of-00032 [Content-Type=application/octet-stream]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \rCopying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00014-of-00032 [Content-Type=application/octet-stream]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \rCopying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00013-of-00032 [Content-Type=application/octet-stream]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \rCopying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/config.json [Content-Type=application/json]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \rCopying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00027-of-00032 [Content-Type=application/octet-stream]...\n",
            "/ [0/37 files][    0.0 B/ 12.3 GiB]   0% Done                                   \rCopying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00017-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00003-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00006-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00012-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00021-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00011-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00026-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00023-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00016-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00005-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/index.html.tmp [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.index [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00029-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00019-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00008-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00030-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00024-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00028-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00004-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00022-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00018-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00010-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00002-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00031-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.meta [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00015-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00009-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00025-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/model.ckpt-362000.data-00007-of-00032 [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/GPT3_XL/checkpoint [Content-Type=application/octet-stream]...\n",
            "/\n",
            "Operation completed over 37 objects/12.3 GiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnqkKBTOn0ox"
      },
      "source": [
        "If everything has worked successfully you should now see your model listed in your bucket below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80t9MMionm2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381808a7-dfc4-4a70-cb89-8d066b2a76ed"
      },
      "source": [
        "!gsutil ls $bucket_base"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://eleutherai/GPT3_XL/\n",
            "gs://eleutherai/gptneo-release/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDKL8fCSoApL"
      },
      "source": [
        "Now we want to make a few modifications to the model config in order to get training working on colab and finetune on your chosen dataset. If you are sampling from our pretrained models, you do not need to make any modifications.\n",
        "\n",
        "You can change parameters below. \n",
        "\n",
        "* `path_to_model` should point to the model weights location in your cloud bucket, and will default to `$bucket_base/${pretrained_model}` if nothing is entered.\n",
        "\n",
        "* `batch_size` is your train batch size - if you're encountering memory errors, try lowering this.\n",
        "\n",
        "* `dataset_name` is the name of your dataset, if nothing is entered, this should default to the dataset you selected in the `Prepare Data` section.\n",
        "\n",
        "* `mesh_shape` specifies the way the model will be divided up across the TPU cores. We suggest leaving this alone unless you know what you're doing.\n",
        "\n",
        "* `train_steps` specifies how many steps you want the model to finetune for. We set this to 1000 for demonstrative purposes but you may need to increase this a little depending on your goals.\n",
        "\n",
        "* `steps_per_checkpoint` specifies how often you want to save model weights during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Laf0slBMDCUj",
        "cellView": "form"
      },
      "source": [
        "# @title Modify config for colab. \n",
        "  \n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "path_to_model = \"\" #@param {type:\"string\"}\n",
        "batch_size = 16 #@param {type:\"integer\"}\n",
        "dset = \"\"  #@param {type:\"string\"}\n",
        "mesh_shape = \"x:4,y:2\" #@param {type:\"string\"}\n",
        "train_steps = 1000 #@param {type:\"integer\"}\n",
        "steps_per_checkpoint = 500 #@param {type:\"integer\"}\n",
        "start_step = 400000 if pretrained_model == \"GPT3_2-7B\" else 362000\n",
        "\n",
        "if path_to_model == \"\":\n",
        "  path_to_model = f'{bucket_base.strip(\"/\")}/{pretrained_model}'\n",
        "print(f'MODEL PATH: {path_to_model}\\n')\n",
        "\n",
        "if dset == \"\":\n",
        "  dset = dataset\n",
        "\n",
        "def pad_to_multiple_of(n, mult):\n",
        "  \"\"\"\n",
        "  pads n to a multiple of mult\n",
        "  \"\"\"\n",
        "  extra = n % mult\n",
        "  if extra > 0:\n",
        "      n = n + mult - extra\n",
        "  return n\n",
        "\n",
        "with open(f'/content/GPTNeo/the-eye.eu/eleuther_staging/gptneo-release/{pretrained_model}/config.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "  pprint(data)\n",
        "  mods = {\n",
        "          \"mesh_shape\": mesh_shape,\n",
        "          \"layout\": \"intermediate_expanded:x,heads:x,memory_length:y,embd:y\",\n",
        "          \"model_path\": path_to_model,\n",
        "          \"datasets\": [[dataset, None, None, None]],\n",
        "          \"train_steps\": start_step + train_steps,\n",
        "          \"eval_steps\": 0,\n",
        "          \"train_batch_size\": batch_size\n",
        "        }\n",
        "  data.update(mods)\n",
        "  print('\\n--->\\n')\n",
        "  pprint(data)\n",
        "  with open(f'configs/{pretrained_model}.json', 'w') as outfile:\n",
        "    json.dump(data, outfile, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPwwbPCA6O7r"
      },
      "source": [
        "# Begin Fine-Tuning\n",
        "\n",
        "If you are fine-tuning the pretrained model, this line of code will begin the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YlaHzyXuMaj"
      },
      "source": [
        "!python3 main.py --model $pretrained_model --steps_per_checkpoint $steps_per_checkpoint --tpu colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_HxtEmBGTGT"
      },
      "source": [
        "## Sample from your model\n",
        "\n",
        "Once training is finished, you can run the same command with the --predict flag to sample from your model.\n",
        "\n",
        "To pass in a prompt, save it to a .txt file, and pass in the name of the file with the --prompt flag.\n",
        "\n",
        "use the cell below to enter your prompt, and run it to save it to example_prompt.txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQE1Y5wPFx7h"
      },
      "source": [
        "%%writefile example_prompt.txt\n",
        "In a shocking finding, scientists discovered a herd of unicorns living in a remote,\n",
        "previously unexplored valley, in the Andes Mountains. Even more surprising to the\n",
        "researchers was the fact that the unicorns spoke perfect English."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf_5E4fHFQIh"
      },
      "source": [
        "!python3 main.py --model $pretrained_model --steps_per_checkpoint 500 --tpu colab --predict --prompt example_prompt.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}