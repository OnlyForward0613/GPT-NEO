{
   "no_dataset": true,
   "n_head": 8,
   "n_vocab": 32,
   "embed_dropout":0.1,
   "lr":0.0001,
   "lr_decay":"cosine",
   "warmup_steps":0,
   "beta1_adam":0.9,
   "beta1":0.9,
   "beta2":0.999,
   "epsilon":1e-09,
   "ada_epsilon1":1e-30,
   "ada_epsilon2":0.001,
   "opt_name":"adam",
   "weight_decay":0.1,
   "train_batch_size":32,
   "attn_dropout":0.1,
   "train_steps":300000,
   "eval_steps":0,
   "predict_steps": 0,
   "res_dropout":0.1,
   "eval_batch_size":1,
   "iterations":500,
   "n_embd":512,
   "model":"GPT2",
   "model_path":"./.test/gpt_test",
   "n_ctx":512,
   "n_layer":1,
   "scale_by_depth": false,
   "scale_by_in": false,
   "mesh_shape":"",
   "layout":"",
   "activation_function":"gelu",
   "attention_types":[
      [["global"], 1]
   ],
   "auto_layout": false,
   "auto_layout_and_mesh_shape": false,
   "use_tpu": false,
   "num_cores":256,
   "steps_per_checkpoint":100,
   "gradient_clipping": 0.5,
   "scalenorm": true,
   "no_weight_tie": false,
   "remove_partial_sequences": true,
   "eos_id": 2,
   "padding_id": 0
}
